<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Statistics Mooc</title>
  <meta name="description" content="This is the notebook for Berkley’s Edx course serise - stat2.1, stat2.2, stat2.3.">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/2017/05/09/Stats_MOOC.html">
  <link rel="alternate" type="application/rss+xml" title="zjuwhw's blog" href="http://localhost:4000/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">zjuwhw's blog</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/links/">Links</a>
          
        
          
        
          
          <a class="page-link" href="/tags/">Tags</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Statistics Mooc</h1>
    <p class="post-meta"><time datetime="2017-05-09T00:00:00+10:00" itemprop="datePublished">May 9, 2017</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>This is the notebook for Berkley’s Edx course serise - <a href="https://www.edx.org/course/introduction-statistics-descriptive-uc-berkeleyx-stat2-1x">stat2.1</a>, <a href="https://www.edx.org/course/introduction-statistics-probability-uc-berkeleyx-stat2-2x">stat2.2</a>, <a href="https://www.edx.org/course/introduction-statistics-inference-uc-berkeleyx-stat2-3x">stat2.3</a>.</p>

<ul id="markdown-toc">
  <li><a href="#stat21-descriptive-statistics" id="markdown-toc-stat21-descriptive-statistics">Stat2.1 Descriptive Statistics</a>    <ul>
      <li><a href="#1-introduction" id="markdown-toc-1-introduction">1. Introduction</a>        <ul>
          <li><a href="#11-why-study-descriptive-statistics" id="markdown-toc-11-why-study-descriptive-statistics">1.1 Why study descriptive statistics?</a></li>
          <li><a href="#12-variables-terminology" id="markdown-toc-12-variables-terminology">1.2 Variables terminology</a></li>
          <li><a href="#13-bar-graphs-describing-categorical-data" id="markdown-toc-13-bar-graphs-describing-categorical-data">1.3 Bar graphs: describing categorical data</a></li>
        </ul>
      </li>
      <li><a href="#2-the-histogram" id="markdown-toc-2-the-histogram">2 The histogram</a>        <ul>
          <li><a href="#21-describing-one-quantitative-variable" id="markdown-toc-21-describing-one-quantitative-variable">2.1 Describing one quantitative variable</a></li>
          <li><a href="#22-how-to-draw-a-histogram" id="markdown-toc-22-how-to-draw-a-histogram">2.2 How to draw a histogram</a></li>
          <li><a href="#23-units-and-density" id="markdown-toc-23-units-and-density">2.3 Units and density</a></li>
          <li><a href="#24-percentiles-estimaing-from-histogram" id="markdown-toc-24-percentiles-estimaing-from-histogram">2.4 Percentiles: estimaing from histogram</a></li>
          <li><a href="#25-percentiles-more-carefully-from-the-data" id="markdown-toc-25-percentiles-more-carefully-from-the-data">2.5 Percentiles: more carefully, from the data</a></li>
        </ul>
      </li>
      <li><a href="#3-measures-of-location" id="markdown-toc-3-measures-of-location">3 Measures of Location</a>        <ul>
          <li><a href="#31-the-median-and-the-mode" id="markdown-toc-31-the-median-and-the-mode">3.1 The median and the mode</a></li>
          <li><a href="#32-the-average-calculation-and-basic-properties" id="markdown-toc-32-the-average-calculation-and-basic-properties">3.2 The average: calculation and basic properties</a></li>
          <li><a href="#33-comparing-and-combining-averages" id="markdown-toc-33-comparing-and-combining-averages">3.3 Comparing and combining averages</a></li>
          <li><a href="#34-the-average-and-the-histogram-the-average-and-the-median" id="markdown-toc-34-the-average-and-the-histogram-the-average-and-the-median">3.4 The average and the histogram; the average and the median</a></li>
          <li><a href="#35-markovs-inequality" id="markdown-toc-35-markovs-inequality">3.5 Markov’s inequality</a></li>
        </ul>
      </li>
      <li><a href="#4-measures-of-spread" id="markdown-toc-4-measures-of-spread">4 Measures of spread</a>        <ul>
          <li><a href="#41-range-and-interquartile-range" id="markdown-toc-41-range-and-interquartile-range">4.1 Range and interquartile range</a></li>
          <li><a href="#42-deviations-from-average-the-standard-deviation-sd" id="markdown-toc-42-deviations-from-average-the-standard-deviation-sd">4.2 Deviations from average; the standard deviation (SD)</a></li>
          <li><a href="#43-properties-of-the-sd-chebychevs-inequality" id="markdown-toc-43-properties-of-the-sd-chebychevs-inequality">4.3 Properties of the SD; Chebychev’s inequality</a></li>
          <li><a href="#44-changing-units-of-measurement-standard-units" id="markdown-toc-44-changing-units-of-measurement-standard-units">4.4 Changing units of measurement; standard units</a></li>
        </ul>
      </li>
      <li><a href="#5-the-normal-curve" id="markdown-toc-5-the-normal-curve">5 The normal curve</a>        <ul>
          <li><a href="#51-bell-shaped-curves-the-standard-normal-curve" id="markdown-toc-51-bell-shaped-curves-the-standard-normal-curve">5.1 Bell shaped curves; the standard normal curve</a></li>
          <li><a href="#52-normal-curves-relation-to-the-standard-normal" id="markdown-toc-52-normal-curves-relation-to-the-standard-normal">5.2 Normal curves: relation to the standard normal</a></li>
          <li><a href="#53-approximating-data-histograms-percentiles-revisited" id="markdown-toc-53-approximating-data-histograms-percentiles-revisited">5.3 Approximating data histograms; percentiles revisited</a></li>
          <li><a href="#54-not-all-histograms-are-bell-shaped-chebychev-revisited" id="markdown-toc-54-not-all-histograms-are-bell-shaped-chebychev-revisited">5.4 Not all histograms are bell shaped; Chebychev revisited</a></li>
        </ul>
      </li>
      <li><a href="#6-relation-between-two-variables" id="markdown-toc-6-relation-between-two-variables">6 Relation between two variables</a>        <ul>
          <li><a href="#61-scatter-diagrams" id="markdown-toc-61-scatter-diagrams">6.1 Scatter diagrams</a></li>
          <li><a href="#62-the-correlation-coefficient-calculation-and-properties" id="markdown-toc-62-the-correlation-coefficient-calculation-and-properties">6.2 The correlation coefficient: calculation and properties</a></li>
          <li><a href="#63-using-r-with-cation" id="markdown-toc-63-using-r-with-cation">6.3 Using r: with cation</a></li>
        </ul>
      </li>
      <li><a href="#7-regression" id="markdown-toc-7-regression">7 Regression</a>        <ul>
          <li><a href="#71-estimation-bivariate-normal-football-shaped-scatter-diagrams" id="markdown-toc-71-estimation-bivariate-normal-football-shaped-scatter-diagrams">7.1 Estimation; bivariate normal (“football shaped”) scatter diagrams</a></li>
          <li><a href="#72-regression-line-intuition-the-equation-in-standard-units-regression-estimates" id="markdown-toc-72-regression-line-intuition-the-equation-in-standard-units-regression-estimates">7.2 Regression line: intuition; the equation in standard units; regression estimates</a></li>
          <li><a href="#73-regression-effect-galton-and-the-regression-fallacy" id="markdown-toc-73-regression-effect-galton-and-the-regression-fallacy">7.3 Regression effect, Galton, and the regression fallacy</a></li>
          <li><a href="#74-equation-of-the-regression-line" id="markdown-toc-74-equation-of-the-regression-line">7.4 Equation of the regression line</a></li>
        </ul>
      </li>
      <li><a href="#8-error-in-the-regression-estimate" id="markdown-toc-8-error-in-the-regression-estimate">8 Error in the regression estimate</a>        <ul>
          <li><a href="#81-least-squares-why-the-regression-line-and-no-other" id="markdown-toc-81-least-squares-why-the-regression-line-and-no-other">8.1 Least squares: why the regression line and no other</a></li>
          <li><a href="#82-the-rms-error-of-regression-calculations-assuming-bivariate-normal-scatter" id="markdown-toc-82-the-rms-error-of-regression-calculations-assuming-bivariate-normal-scatter">8.2 The r.m.s error of regression; calculations assuming bivariate normal scatter</a></li>
          <li><a href="#83-how-regression-is-commonly-used-estimating-an-unknown-true-line" id="markdown-toc-83-how-regression-is-commonly-used-estimating-an-unknown-true-line">8.3 How regression is commonly used; estimating an “unknown true line”</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#stat22-probability" id="markdown-toc-stat22-probability">Stat2.2 Probability</a>    <ul>
      <li><a href="#1-the-two-fundamental-rules" id="markdown-toc-1-the-two-fundamental-rules">1 the two fundamental rules</a>        <ul>
          <li><a href="#11-what-is-probability" id="markdown-toc-11-what-is-probability">1.1 What is probability?</a></li>
          <li><a href="#12-addition-rule" id="markdown-toc-12-addition-rule">1.2 Addition rule</a></li>
          <li><a href="#13-multiplication-rule" id="markdown-toc-13-multiplication-rule">1.3 Multiplication rule</a></li>
          <li><a href="#14-problem-solving-techniques" id="markdown-toc-14-problem-solving-techniques">1.4 Problem-solving techniques</a></li>
          <li><a href="#15-conditional-or-unconditional" id="markdown-toc-15-conditional-or-unconditional">1.5 Conditional or unconditional?</a></li>
          <li><a href="#16-bayes-rule" id="markdown-toc-16-bayes-rule">1.6 Bayes’ Rule</a></li>
        </ul>
      </li>
      <li><a href="#2-random-sampling-with-and-without-replacement" id="markdown-toc-2-random-sampling-with-and-without-replacement">2 Random sampling with and without replacement</a>        <ul>
          <li><a href="#21-independence" id="markdown-toc-21-independence">2.1 Independence</a></li>
          <li><a href="#22-sampling-with-replacement-the-binomial-formula二项分布" id="markdown-toc-22-sampling-with-replacement-the-binomial-formula二项分布">2.2 Sampling with replacement: the binomial formula（二项分布）</a></li>
          <li><a href="#23-sampling-without-replacement-the-hypergeometric超几何-formula" id="markdown-toc-23-sampling-without-replacement-the-hypergeometric超几何-formula">2.3 Sampling without replacement: the hypergeometric（超几何） formula</a></li>
          <li><a href="#24-examples" id="markdown-toc-24-examples">2.4 Examples</a></li>
        </ul>
      </li>
      <li><a href="#3-the-law-of-averages-and-expected-values" id="markdown-toc-3-the-law-of-averages-and-expected-values">3 the law of averages and expected values</a>        <ul>
          <li><a href="#31-not-the-law-of-averages" id="markdown-toc-31-not-the-law-of-averages">3.1 Not the law of averages</a></li>
          <li><a href="#32-the-law-of-averages" id="markdown-toc-32-the-law-of-averages">3.2 The law of averages</a></li>
          <li><a href="#33-the-expected-value-of-a-random-sum" id="markdown-toc-33-the-expected-value-of-a-random-sum">3.3 The expected value of a random sum</a></li>
          <li><a href="#34-the-expected-value-of-a-random-average" id="markdown-toc-34-the-expected-value-of-a-random-average">3.4 The expected value of a random average</a></li>
        </ul>
      </li>
      <li><a href="#4-the-central-limit-theorem" id="markdown-toc-4-the-central-limit-theorem">4 the central limit theorem</a>        <ul>
          <li><a href="#41-the-standard-error-of-a-random-sum" id="markdown-toc-41-the-standard-error-of-a-random-sum">4.1 The standard error of a random sum</a></li>
          <li><a href="#42-probabilities-for-the-sum-of-a-large-sample" id="markdown-toc-42-probabilities-for-the-sum-of-a-large-sample">4.2 Probabilities for the sum of a large sample</a></li>
          <li><a href="#43-the-central-limit-theorem" id="markdown-toc-43-the-central-limit-theorem">4.3 The Central limit theorem</a></li>
          <li><a href="#44-the-scope-of-the-normal-approximation" id="markdown-toc-44-the-scope-of-the-normal-approximation">4.4 The scope of the normal approximation</a></li>
        </ul>
      </li>
      <li><a href="#5-the-accuracy-of-simple-random-samples" id="markdown-toc-5-the-accuracy-of-simple-random-samples">5 the accuracy of simple random samples</a>        <ul>
          <li><a href="#51-errors-in-random-percents-and-averages" id="markdown-toc-51-errors-in-random-percents-and-averages">5.1 Errors in random percents and averages</a></li>
          <li><a href="#52-sampling-without-replacement-the-correction-factor" id="markdown-toc-52-sampling-without-replacement-the-correction-factor">5.2 Sampling without replacement: the correction factor</a></li>
          <li><a href="#53-accuracy" id="markdown-toc-53-accuracy">5.3 Accuracy</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#stat23-inference" id="markdown-toc-stat23-inference">Stat2.3 Inference</a></li>
  <li><a href="#appendix" id="markdown-toc-appendix">Appendix</a>    <ul>
      <li><a href="#appendix-1--the-greek-symbols" id="markdown-toc-appendix-1--the-greek-symbols">Appendix 1 : The Greek Symbols</a></li>
      <li><a href="#appendix-2--common-distribution" id="markdown-toc-appendix-2--common-distribution">Appendix 2 : Common Distribution</a></li>
    </ul>
  </li>
</ul>

<h2 id="stat21-descriptive-statistics">Stat2.1 Descriptive Statistics</h2>

<h3 id="1-introduction">1. Introduction</h3>

<h4 id="11-why-study-descriptive-statistics">1.1 Why study descriptive statistics?</h4>

<ul>
  <li>Statistics: The science f drawing conclusions from data</li>
  <li>Descriptive statistics: Describing and summarizing data</li>
  <li>Probability: Understanding and quantifying randomness</li>
  <li>
    <p>Inference: Making conclusions based on data from random samples</p>
  </li>
  <li>Graphical descriptions –&gt; Numerical summaries; single variable –&gt; relation between two variables</li>
</ul>

<h4 id="12-variables-terminology">1.2 Variables terminology</h4>

<ul>
  <li>quantitative variables</li>
  <li>contiuous and discrete</li>
  <li>categorical and qualitative</li>
</ul>

<h4 id="13-bar-graphs-describing-categorical-data">1.3 Bar graphs: describing categorical data</h4>

<h3 id="2-the-histogram">2 The histogram</h3>

<h4 id="21-describing-one-quantitative-variable">2.1 Describing one quantitative variable</h4>

<ul>
  <li>Stem and leaf plot</li>
</ul>

<h4 id="22-how-to-draw-a-histogram">2.2 How to draw a histogram</h4>

<ul>
  <li>show the distribution</li>
  <li>allows for the bariable to be “binned” into unequal intervals</li>
</ul>

<h4 id="23-units-and-density">2.3 Units and density</h4>

<h4 id="24-percentiles-estimaing-from-histogram">2.4 Percentiles: estimaing from histogram</h4>

<ul>
  <li>famous percentiles
    <ul>
      <li>25th percentile = lower quartile</li>
      <li>50th percentile = median</li>
      <li>75th percentile = upper quartile</li>
    </ul>
  </li>
</ul>

<h4 id="25-percentiles-more-carefully-from-the-data">2.5 Percentiles: more carefully, from the data</h4>

<h3 id="3-measures-of-location">3 Measures of Location</h3>

<h4 id="31-the-median-and-the-mode">3.1 The median and the mode</h4>

<ul>
  <li>Mode: the value that has the highest frequency</li>
  <li>Unimodal: one peak</li>
</ul>

<h4 id="32-the-average-calculation-and-basic-properties">3.2 The average: calculation and basic properties</h4>

<ul>
  <li>average/mean: add up all the entries in the list, then divide by the number of entries
    <ul>
      <li>Units of the average: same as the units of the list</li>
    </ul>
  </li>
</ul>

<h4 id="33-comparing-and-combining-averages">3.3 Comparing and combining averages</h4>

<h4 id="34-the-average-and-the-histogram-the-average-and-the-median">3.4 The average and the histogram; the average and the median</h4>

<ul>
  <li>The median is unaffected by outliers</li>
  <li>In a right-skewed distribution, the average is greater than the median</li>
</ul>

<h4 id="35-markovs-inequality">3.5 Markov’s inequality</h4>

<ul>
  <li>Markov’s inequality: If a list has only non-negative entries, then the proportion of entries that are &gt;= k times the average is at most 1/k (k can be any positive number)</li>
  <li>For example:
    <ul>
      <li>Q: the average age of a group of people is 20 years. What proportion are more than 80 years old?</li>
      <li>A: The proportion is <strong>at most</strong> 1/4 (k=4)</li>
    </ul>
  </li>
</ul>

<h3 id="4-measures-of-spread">4 Measures of spread</h3>

<h4 id="41-range-and-interquartile-range">4.1 Range and interquartile range</h4>

<ul>
  <li>range = maximum - minimum</li>
  <li>interquartile range (IQR) = upper quartile - lower quartile</li>
  <li>“The IQR of data is 8 years” means “the middle 50% of the data are distributed over 8 years”</li>
</ul>

<h4 id="42-deviations-from-average-the-standard-deviation-sd">4.2 Deviations from average; the standard deviation (SD)</h4>

<ul>
  <li>deviation from average = value - average</li>
  <li>standard deviation (SD) = root mean square (r.m.s.) of deviations from average</li>
  <li>variance = mean sequare of deviations from average</li>
  <li>The average and the SD have the same units</li>
</ul>

<p><img src="/images/SD_formula1.png" alt="" /></p>

<ul>
  <li>The vexed question of n-1</li>
</ul>

<p><img src="/images/SD_formula2.png" alt="" /></p>

<p>In some situations where you are trying to use the SD of a sample to estimate the SD of the population from which the sample was drawn, then according to some criteria, it might be better to use n-1 instead of n in the denominator.</p>

<h4 id="43-properties-of-the-sd-chebychevs-inequality">4.3 Properties of the SD; Chebychev’s inequality</h4>

<ul>
  <li>Pafnuty Lvovich Chebychev (1821-1894)</li>
  <li>Chebychev’s inequality: In any list, the proportion of the entries that are k or more SDs away from the average is at most 1/k<sup>2</sup></li>
  <li><strong>Rough statement</strong>: No matter what the list, the vast majority of entries will be in the range <strong>average ± a few SDs</strong></li>
  <li><strong>Precise statment</strong>: No matter what the list, a proportion of at least 1-1/k<sup>2</sup> of the entries will be in the range <strong>average ± a few SDs</strong></li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>Typical use

Age: average 20 years, SD 5 years.
What percent are more than 80 years old?

Markov's bound:
at most 25% (1/k, k = 80/20 = 4)

Chebychev's bound: 
at most 0.7% (1/k^2, k=(80-20)/5 = 12)

In conclusion, both bounds are correct.
But Chebychev's bound is much sharper.
Because it uses the SD, not just the average.
</code></pre>
</div>

<h4 id="44-changing-units-of-measurement-standard-units">4.4 Changing units of measurement; standard units</h4>

<ul>
  <li>Mechanics of changing units
    <ul>
      <li>Multiplying by a constant, e.g. centimeters = 2.54 * inches</li>
      <li>Mutliplying by a constant, then adding a constant, e.g. ◦F = (9/5)◦C + 32</li>
      <li>Can also first add a constant, then mulitple by a constant, e.g. new variable = (old variable + b) * a</li>
    </ul>
  </li>
  <li>Adding a constant
    <ul>
      <li>new average = old everage + constant</li>
      <li>new SD = old SD</li>
    </ul>
  </li>
  <li>Multiplying by a constant
    <ul>
      <li>new average = old average * constant</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>new SD = old SD *</td>
              <td>constant</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>Linear transformations: new list = a * (old list) + b
    <ul>
      <li>new average = a * (old average) + b</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>new SD =</td>
              <td>a</td>
              <td>* (old SD)</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>Standard units: the z-score
    <ul>
      <li>z = (x - average)/SD</li>
      <li>x = z * SD + average</li>
      <li>z measures “how many SDs above average”</li>
      <li>the average of any list in standard units is 0</li>
      <li>the SD of any list in standard units is 1</li>
      <li>the vast majority (at least 8/9) of any list in standard units will be in the range -3 to 3</li>
    </ul>
  </li>
</ul>

<h3 id="5-the-normal-curve">5 The normal curve</h3>

<h4 id="51-bell-shaped-curves-the-standard-normal-curve">5.1 Bell shaped curves; the standard normal curve</h4>

<ul>
  <li>A bell shaped distribution</li>
</ul>

<p><img src="/images/Bell_shaped.png" alt="" /></p>

<ul>
  <li>The standard normal curve</li>
</ul>

<p><img src="/images/standard_normal_curve.png" alt="" /></p>

<p><img src="/images/standard_normal_curve_density.png" alt="" /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>Useful to remember

total area = 1
balance point: z=0
points of inflection: z=-1, z=1

Central areas:
between z=-1 and z=1: about 68%
between z=-2 and z=2: about 95%

Tail areas:
to the left of -1: about 16%
to the right of 1: about 16%
to the left of -2: about 2.5%
to the right of 2: about 2.5%

Percentiles:
95th percentils: z=1.65, roughly
5th percentile: z=-1.65, roughly
</code></pre>
</div>

<h4 id="52-normal-curves-relation-to-the-standard-normal">5.2 Normal curves: relation to the standard normal</h4>

<ul>
  <li>The normal curve withe mean μ and SD σ</li>
</ul>

<p><img src="/images/normal_curve_density.png" alt="" /></p>

<ul>
  <li>Finding a percent under a normal curve</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>For a list with average 67 and SD 3,
what percent are between 63 and 67?

(63-67)/3 = -1.33 standard units
67 = 0 standard units

So, the question becomes:
Under standard normal curve,
what percent are between -1.33 and 0?

The applet says the area is 40.82%.
In R, the expression is "pnorm(0) - pnorm(-1.33)"
</code></pre>
</div>

<h4 id="53-approximating-data-histograms-percentiles-revisited">5.3 Approximating data histograms; percentiles revisited</h4>

<h4 id="54-not-all-histograms-are-bell-shaped-chebychev-revisited">5.4 Not all histograms are bell shaped; Chebychev revisited</h4>

<h3 id="6-relation-between-two-variables">6 Relation between two variables</h3>

<h4 id="61-scatter-diagrams">6.1 Scatter diagrams</h4>

<ul>
  <li>univariate data: histogram</li>
  <li>bivariate data: scatter diagram</li>
  <li>association: any relation between variables</li>
  <li>positive association</li>
  <li>negative association</li>
  <li>linear association</li>
</ul>

<h4 id="62-the-correlation-coefficient-calculation-and-properties">6.2 The correlation coefficient: calculation and properties</h4>

<ul>
  <li>correlation coefficient (r): a number between -1 and 1; it measures linear association, that is, how tightly the points are clustered about a straight line</li>
</ul>

<p><img src="/images/correlation_coefficent.png" alt="" /></p>

<ul>
  <li>r is a pure number with no units</li>
  <li>-1 &lt;= r &lt;= 1</li>
  <li>It doesn’t matter if you switch the variables x and y; r stays the same</li>
  <li>Adding a constant to one of the lists, r stays the same</li>
  <li>Multiplying one the lists by a positve constant, r stays the same</li>
  <li>Multiplying just one (not both) of the list by a negative constant, r changes to -r</li>
</ul>

<h4 id="63-using-r-with-cation">6.3 Using r: with cation</h4>

<ul>
  <li>Association is not causation</li>
  <li>r measures linear association</li>
  <li>correlated: <strong>linearly</strong> related</li>
  <li>Even one outlier can have a noticeable effect on r</li>
</ul>

<h3 id="7-regression">7 Regression</h3>

<h4 id="71-estimation-bivariate-normal-football-shaped-scatter-diagrams">7.1 Estimation; bivariate normal (“football shaped”) scatter diagrams</h4>

<ul>
  <li>Estimation: one variable, pick one value to estimate.
    <ul>
      <li>natural estimate: the average</li>
      <li>math fact: The r.m.s. of the errors will be smallest if you choose estimator = average.</li>
      <li>average: least squares estimate</li>
    </ul>
  </li>
  <li>Estimation: two variables, given the value of one variable, estimate the value of the other
    <ul>
      <li>If the scater diagram is roughly football shaped, you can assume:
        <ul>
          <li>the distributions of both the variables are roughly normal</li>
          <li>the distribution of values in each vertical and horizontal strip is roughly normal</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="72-regression-line-intuition-the-equation-in-standard-units-regression-estimates">7.2 Regression line: intuition; the equation in standard units; regression estimates</h4>

<ul>
  <li>estimate of y (in standard units) = r * x (in standard units), r is the correlation coefficient</li>
</ul>

<h4 id="73-regression-effect-galton-and-the-regression-fallacy">7.3 Regression effect, Galton, and the regression fallacy</h4>

<h4 id="74-equation-of-the-regression-line">7.4 Equation of the regression line</h4>

<ul>
  <li>the equation in three ways</li>
</ul>

<p><img src="/images/regression_equation.png" alt="" /></p>

<h3 id="8-error-in-the-regression-estimate">8 Error in the regression estimate</h3>

<h4 id="81-least-squares-why-the-regression-line-and-no-other">8.1 Least squares: why the regression line and no other</h4>

<ul>
  <li>How much error?
    <ul>
      <li>error = vertical distance between the point and the line, for every point in the scatter diagram</li>
      <li>rough size of error = r.m.s of errors</li>
    </ul>
  </li>
  <li>regreesion line: least squares line</li>
</ul>

<h4 id="82-the-rms-error-of-regression-calculations-assuming-bivariate-normal-scatter">8.2 The r.m.s error of regression; calculations assuming bivariate normal scatter</h4>

<ul>
  <li>r.m.s. error of regression = r.m.s. of residuals = sqrt(1-r<sup>2</sup>) * SD of y
    <ul>
      <li>r = 1 or -1: r.m.s. error of regression = 0, which says, scatter is a perfect straight line; regression makes no error.</li>
      <li>r = 0: r.m.s. error of regression = SD of y, which says, no linear association; regression is the same as using the average.</li>
      <li>All other r: Regression is not perfect, but better than using the average.</li>
    </ul>
  </li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: left">one variable</th>
      <th style="text-align: left">two variables</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">normal curve</td>
      <td style="text-align: left">football shaped scatter diagram</td>
    </tr>
    <tr>
      <td style="text-align: left">average</td>
      <td style="text-align: left">regression line</td>
    </tr>
    <tr>
      <td style="text-align: left">SD</td>
      <td style="text-align: left">r.m.s. error of regression</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>Some useful analogies
    <ul>
      <li>For about 68% of the points, the regression estimate of correct to within 1 r.m.s. error.</li>
      <li>For about 95% of the points, the regression estimate is correct to within 2 r.m.s. errors.</li>
    </ul>
  </li>
  <li>Residual plot
    <ul>
      <li>the average of the residuals is always 0</li>
      <li>there is no linear association between the residuals and x</li>
      <li>the residual plot cannot show any trend or linear relation</li>
      <li>Good regression: residual plot looks like a formless blob around the horizontal axis</li>
    </ul>
  </li>
</ul>

<h4 id="83-how-regression-is-commonly-used-estimating-an-unknown-true-line">8.3 How regression is commonly used; estimating an “unknown true line”</h4>

<h2 id="stat22-probability">Stat2.2 Probability</h2>

<h3 id="1-the-two-fundamental-rules">1 the two fundamental rules</h3>

<h4 id="11-what-is-probability">1.1 What is probability?</h4>

<ul>
  <li>probability of an event = number of outcomes in the event / total number of outcomes</li>
  <li>Frequency theory, long run proportion</li>
  <li>Many probabilities can’t interpreted as long run frequencies, because they are based on experiments that can’t be repeated under identical conditions</li>
</ul>

<h4 id="12-addition-rule">1.2 Addition rule</h4>

<ul>
  <li>Probabilities are numbers between 0 and 1</li>
  <li>Notation
    <ul>
      <li>P(A) is read as “the probability that the event A occurs”</li>
      <li>P(A): “probability of A”</li>
      <li>P(coin lands heads), P(heads), P(H)</li>
    </ul>
  </li>
  <li>Venn diagrams</li>
  <li>Addition rule: P(A or B) = P(A) + P(B), if A and B are mutually exclusive.</li>
  <li>inclusion-exclusion formula: P(A or B) = P(A) + P(B) - P(A and B) for all A and B</li>
  <li>Complement rule: P(not A) = 1 - P(A)</li>
</ul>

<h4 id="13-multiplication-rule">1.3 Multiplication rule</h4>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>P(B</td>
          <td>A): <strong>conditional probability</strong> of B, given that A has happened</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Multiplication Rule: P(A and B) = P(A) * P(B</td>
          <td>A) for all A, B</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h4 id="14-problem-solving-techniques">1.4 Problem-solving techniques</h4>

<ul>
  <li>get started on a solution
    <ul>
      <li>be precise in your use of terminology and notation</li>
      <li>pay attention to detail</li>
      <li>avoid rushing to conclusions</li>
    </ul>
  </li>
</ul>

<h4 id="15-conditional-or-unconditional">1.5 Conditional or unconditional?</h4>

<h4 id="16-bayes-rule">1.6 Bayes’ Rule</h4>

<div class="highlighter-rouge"><pre class="highlight"><code>P(A) = 0.8; P(B) = 0.2; P(bad|A) = 0.01; P(bad|B) = 0.02

P(A and bad)
 = P(A) * P(bad|A)
 = 0.8 * 0.01 
 = 0.008
P(bad)
 = P(A and bad) + P(B and bad) 
 = P(A) * P(bad|A) + P(B) * P(bad|B) 
 = 0.008 + 0.004 
 = 0.012
P(A|bad)
 = P(A and bad) / P(bad) 
 = 0.008/0.012 
 = 0.67
</code></pre>
</div>

<ul>
  <li>Bayes’Rule: Use it to find the conditional probability of an event at an earlier stage, given the result of a later stage.</li>
</ul>

<h3 id="2-random-sampling-with-and-without-replacement">2 Random sampling with and without replacement</h3>

<h4 id="21-independence">2.1 Independence</h4>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Definition of conditional probability: P(A and B) = P(A) * P(B</td>
          <td>A); P(B</td>
          <td>A) = P(A and B)/P(A)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>independent trials
    <ul>
      <li>tosses of a coin</li>
      <li>rolls of a die</li>
      <li>draws with replacement</li>
    </ul>
  </li>
  <li>dependent trials
    <ul>
      <li>cards dealt from a deck</li>
      <li>draws without replacement</li>
    </ul>
  </li>
  <li>Independent events
    <ul>
      <li>
        <table>
          <tbody>
            <tr>
              <td>Two events A and B are independent if P(B</td>
              <td>A) = P(B</td>
              <td>not A) = P`(B)</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>P(A and B) = P(A) * P(B), if A and B are independent</li>
    </ul>
  </li>
</ul>

<h4 id="22-sampling-with-replacement-the-binomial-formula二项分布">2.2 Sampling with replacement: the binomial formula（二项分布）</h4>

<p><img src="/images/binomial_formal.png" alt="" /></p>

<h4 id="23-sampling-without-replacement-the-hypergeometric超几何-formula">2.3 Sampling without replacement: the hypergeometric（超几何） formula</h4>

<p><img src="/images/hypergeometric_formula.png" alt="" /></p>

<h4 id="24-examples">2.4 Examples</h4>

<ul>
  <li>geometric distribution: waiting time till the first sucess; (1-p)<sup>k-1</sup>*(p) for k = 1, 2, 3…</li>
  <li>negative binomial probabilites</li>
</ul>

<h3 id="3-the-law-of-averages-and-expected-values">3 the law of averages and expected values</h3>

<h4 id="31-not-the-law-of-averages">3.1 Not the law of averages</h4>

<ul>
  <li>move from exact <strong>calculations</strong> to <strong>approximations</strong></li>
  <li>Law of averages:
    <ul>
      <li>As you keep tossing, in the long run you get <strong>about half</strong> heads.</li>
      <li>It is about the <strong>proportion</strong> of heads being close to 1/2.</li>
    </ul>
  </li>
</ul>

<h4 id="32-the-law-of-averages">3.2 The law of averages</h4>

<ul>
  <li>More formal statment
    <ul>
      <li>As you keep tossing, in the long run, the chance that the <strong>proportion of heads</strong> is in the range <strong>0.5 ± a fixed amount</strong> goes to 1</li>
      <li>You can choose the <strong>fixed amount</strong> to be as small as you want, as long as you keep it fixed as the number of tosses goes up.</li>
    </ul>
  </li>
  <li>Law of large numbers
    <ul>
      <li>independent, repeated, success-failur trials</li>
      <li>probability of success on a single trial: p</li>
      <li>As the number of trials increases, the chance that the proportion of successes is in range <strong>p ± a fixed amount</strong> goes to 1.</li>
    </ul>
  </li>
</ul>

<h4 id="33-the-expected-value-of-a-random-sum">3.3 The expected value of a random sum</h4>

<ul>
  <li>Notation:
    <ul>
      <li>random variables: X, Y</li>
      <li>the sum of the first n X’s: S<sub>n</sub> = X<sub>1</sub> + X<sub>2</sub>+ … X<sub>n</sub></li>
    </ul>
  </li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>X: the number of spots on one rool of a die
Probability distribution table for X:
 - spot 1: 1/6
 - spot 2: 1/6
 - spot 3: 1/6
 - spot 4: 1/6
 - spot 5: 1/6
 - spot 6: 1/6

Long run average value of X:
1*1/6 + 2*1/6 + 3*1/6 + 4*1/6 + 5*1/6 + 6*1/6 = 3.5
</code></pre>
</div>

<ul>
  <li>Expected value of X = expectation of X = E(X)</li>
  <li>Let X<sub>1</sub>, X<sub>2</sub>,…, X<sub>n</sub>, be independent and identically distributed (i.i.d.) random variables, and let S<sub>n</sub> = X<sub>1</sub> + X<sub>2</sub>+ … X<sub>n</sub>. Then, E(S<sub>n</sub>) = n*E(X<sub>1</sub>)</li>
  <li>Exected value of the binomial, E(X) = np</li>
</ul>

<h4 id="34-the-expected-value-of-a-random-average">3.4 The expected value of a random average</h4>

<h3 id="4-the-central-limit-theorem">4 the central limit theorem</h3>

<h4 id="41-the-standard-error-of-a-random-sum">4.1 The standard error of a random sum</h4>

<ul>
  <li>Standard error
    <ul>
      <li>The standard error of <strong>a random variable X</strong> is defined by SE(X) = sqrt(E((X-E(X))<sup>2</sup>)</li>
      <li>SE(X) measures the rough sie of the chance error in X: roughly how far off X is from E(X)</li>
    </ul>
  </li>
  <li>Standard deviation
    <ul>
      <li>The standard deviation of <strong>a list of numbers</strong>: SD = r.m.s. of the deviations from average</li>
      <li>The SD measures the rough size of the deviations: roughly how far off the numbers are from the average</li>
    </ul>
  </li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>X: one draw at random from 1,2,2,3

X: 
P(X = 1) = 1/4
P(X = 2) = 1/2
P(X = 3) = 1/4
E(X) = 2 = average of the box

X-E(X)
P(-1) = 1/4
P(0) = 1/2
P(1) = 1/4
E(X-E(X)) = 0

(X-E(X))^2
P(0) = 1/2
P(1) = 1/2
E((X-E(X))^2) = 0.5

standard error of X = SE(X) = sqrt(E((X-E(X))^2)) = 0.71
= SD of the box (note: for one draw, n = 1)
</code></pre>
</div>

<p><img src="/images/SE.png" alt="" /></p>

<h4 id="42-probabilities-for-the-sum-of-a-large-sample">4.2 Probabilities for the sum of a large sample</h4>

<h4 id="43-the-central-limit-theorem">4.3 The Central limit theorem</h4>

<h4 id="44-the-scope-of-the-normal-approximation">4.4 The scope of the normal approximation</h4>

<h3 id="5-the-accuracy-of-simple-random-samples">5 the accuracy of simple random samples</h3>

<h4 id="51-errors-in-random-percents-and-averages">5.1 Errors in random percents and averages</h4>

<h4 id="52-sampling-without-replacement-the-correction-factor">5.2 Sampling without replacement: the correction factor</h4>

<h4 id="53-accuracy">5.3 Accuracy</h4>

<h2 id="stat23-inference">Stat2.3 Inference</h2>

<h2 id="appendix">Appendix</h2>

<h3 id="appendix-1--the-greek-symbols">Appendix 1 : The Greek Symbols</h3>

<p><img src="/images/Greek_Symbol.png" alt="" /></p>

<p>source: <a href="https://zh.wikipedia.org/wiki/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D">https://zh.wikipedia.org/wiki/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D</a></p>

<h3 id="appendix-2--common-distribution">Appendix 2 : Common Distribution</h3>

<p><img src="/images/common_distribution_1.png" alt="" /></p>

<p><img src="/images/common_distribution_2.png" alt="" /></p>

<p>ps: pmf, probability mass function（概率质量函数）; pdf, probability density function（概率密度函数）; mgf, Moment-generating function（动差生成函数）</p>

<p>source: <a href="http://www.stat.tamu.edu/~twehrly/611/distab.pdf">http://www.stat.tamu.edu/~twehrly/611/distab.pdf</a></p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">


    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>zjuwhw's blog</li>
          <li><a href="mailto:zju_whw@163.com">zju_whw@163.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/zjuwhw"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">zjuwhw</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/zjuwhw"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">zjuwhw</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>This is zjuwhw's personal blog. Powered by Jekyll and Host in Github.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
