<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>zjuwhw's blog</title>
    <description>This is zjuwhw's personal blog. Powered by Jekyll and Host in Github.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 14 Jul 2017 14:27:49 +1000</pubDate>
    <lastBuildDate>Fri, 14 Jul 2017 14:27:49 +1000</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Linear Regression in R</title>
        <description>&lt;h3 id=&quot;lm-function&quot;&gt;lm() function&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;summary(lm(Girth ~ Height, data=trees))

## 
## Call:
## lm(formula = Girth ~ Height, data = trees)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.2386 -1.9205 -0.0714  2.7450  4.5384 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept) -6.18839    5.96020  -1.038  0.30772   
## Height       0.25575    0.07816   3.272  0.00276 **
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.728 on 29 degrees of freedom
## Multiple R-squared:  0.2697, Adjusted R-squared:  0.2445 
## F-statistic: 10.71 on 1 and 29 DF,  p-value: 0.002758
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;example-data&quot;&gt;Example data&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X = trees[,&quot;Height&quot;]
Y = trees[,&quot;Girth&quot;]
n = nrow(trees)
Xbar = mean(X)
Ybar = mean(Y)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;point-estimator-b_0-and-b_1&quot;&gt;point estimator $b_{0}$ and $b_{1}$&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{1} = \frac{\sum(X_{i} - \bar{X})(Y_{i} - \bar{Y})}{\sum(X_{i} - \bar{X})^2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{0} = \frac{1}{n}(\sum Y_{i} - b_{1} \sum X_{i}) = \bar{Y} - b_{1}\bar{X}&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;b1 = sum((X - Xbar)*(Y - Ybar))/sum((X-Xbar)^2)
b1

## [1] 0.2557471

b0 = Ybar - b1*Xbar
b0

## [1] -6.188395
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;residuals-sse-and-mse&quot;&gt;Residuals, SSE and MSE&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SSE = \displaystyle\sum_{i=1}^{n}(Y_{i} - \hat{Y}_{i})^{2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{2} = MSE = \frac{SSE}{n-2}&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;residual = Y - b1*X - b0
summary(residual)

##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -4.23862 -1.92051 -0.07138  0.00000  2.74500  4.53840

SSE = sum(residual^2)
SSE

## [1] 215.7722

MSE = SSE/(n-2)
MSE

## [1] 7.44042

sqrt(MSE)

## [1] 2.727713
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;sampling-distribution-of-b_1-and-b_1---beta_1sb_1&quot;&gt;sampling distribution of $b_{1}$ and $(b_{1} - \beta_{1})/s(b_{1})$&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{2}(b_{1}) = \frac{MSE}{\sum(X_{i} - \bar{X})^{2}}&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;s = sqrt( MSE/sum((X - Xbar)^2))
s

## [1] 0.0781583
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(b_{1} - \beta_{1})/s(b_{1}) \sim t(n-2)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H_{0}: \beta_{1} = 0&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;t = b1 / s
t

## [1] 3.272169

(1 - pt(t, n -2))*2

## [1] 0.002757815
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 04 Jul 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/07/04/lr_R.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/07/04/lr_R.html</guid>
        
        <category>statistics</category>
        
        
      </item>
    
      <item>
        <title>Linear Regression</title>
        <description>&lt;p&gt;This is the notebook for the book “&lt;a href=&quot;https://www.amazon.com/Applied-Linear-Regression-Models-Student/dp/0073014664&quot;&gt;Applied Linear Regression Models&lt;/a&gt;”.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#part-1-simple-linear-regression&quot; id=&quot;markdown-toc-part-1-simple-linear-regression&quot;&gt;Part 1 Simple linear regression&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-1-linear-regression-with-one-predictor-variable&quot; id=&quot;markdown-toc-chapter-1-linear-regression-with-one-predictor-variable&quot;&gt;Chapter 1 Linear regression with one predictor variable&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11-relations-between-variables&quot; id=&quot;markdown-toc-11-relations-between-variables&quot;&gt;1.1 Relations between variables&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12-regression-models-and-their-uses&quot; id=&quot;markdown-toc-12-regression-models-and-their-uses&quot;&gt;1.2 Regression Models and Their Uses&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#13-simple-linear-regression-model-with-distribution-of-error-terms-unspecified&quot; id=&quot;markdown-toc-13-simple-linear-regression-model-with-distribution-of-error-terms-unspecified&quot;&gt;1.3 Simple linear regression model with distribution of error terms unspecified&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#14-data-for-regression-analysis&quot; id=&quot;markdown-toc-14-data-for-regression-analysis&quot;&gt;1.4 Data for regression analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#15-overview-of-steps-in-regression-analysis&quot; id=&quot;markdown-toc-15-overview-of-steps-in-regression-analysis&quot;&gt;1.5 Overview of steps in regression analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#16-estimation-of-regression-function&quot; id=&quot;markdown-toc-16-estimation-of-regression-function&quot;&gt;1.6 Estimation of regression function&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#17-estimation-of-erro-terms-variance-sigma2&quot; id=&quot;markdown-toc-17-estimation-of-erro-terms-variance-sigma2&quot;&gt;1.7 Estimation of Erro Terms Variance $\sigma^{2}$&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#18-normal-error-regression-model&quot; id=&quot;markdown-toc-18-normal-error-regression-model&quot;&gt;1.8 Normal Error Regression Model&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-2-inferences-in-regression-and-correlation-analysis&quot; id=&quot;markdown-toc-chapter-2-inferences-in-regression-and-correlation-analysis&quot;&gt;Chapter 2 Inferences in Regression and Correlation Analysis&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#21-inferences-concerning-beta_1&quot; id=&quot;markdown-toc-21-inferences-concerning-beta_1&quot;&gt;2.1 Inferences Concerning $\beta_{1}$&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#22-inferences-concerning-beta_0&quot; id=&quot;markdown-toc-22-inferences-concerning-beta_0&quot;&gt;2.2 Inferences Concerning $\beta_{0}$&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#23-some-considerations-on-making-inferences-concerning-beta_0-and-beta_1&quot; id=&quot;markdown-toc-23-some-considerations-on-making-inferences-concerning-beta_0-and-beta_1&quot;&gt;2.3 Some Considerations on Making Inferences Concerning $\beta_{0}$ and $\beta_{1}$&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#24-interval-estimation-of-ey_h&quot; id=&quot;markdown-toc-24-interval-estimation-of-ey_h&quot;&gt;2.4 Interval Estimation of $E(Y_{h})$&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#25-prediction-of-new-observation&quot; id=&quot;markdown-toc-25-prediction-of-new-observation&quot;&gt;2.5 Prediction of New Observation&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#26-confidence-band-for-regression-line&quot; id=&quot;markdown-toc-26-confidence-band-for-regression-line&quot;&gt;2.6 Confidence Band for Regression Line&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#27-analysis-of-variance-approach&quot; id=&quot;markdown-toc-27-analysis-of-variance-approach&quot;&gt;2.7 Analysis of Variance Approach&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#28-general-linear-test-approach&quot; id=&quot;markdown-toc-28-general-linear-test-approach&quot;&gt;2.8 General Linear Test Approach&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#29-descriptive-measures-of-linear-association-between-x-and-y&quot; id=&quot;markdown-toc-29-descriptive-measures-of-linear-association-between-x-and-y&quot;&gt;2.9 Descriptive Measures of Linear Association between X and Y&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#210-considerations-in-applying-regression-analysis&quot; id=&quot;markdown-toc-210-considerations-in-applying-regression-analysis&quot;&gt;2.10 Considerations in Applying Regression Analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#211-normal-correlation-models&quot; id=&quot;markdown-toc-211-normal-correlation-models&quot;&gt;2.11 Normal Correlation Models&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-3-diagnostics-and-remedial-measures&quot; id=&quot;markdown-toc-chapter-3-diagnostics-and-remedial-measures&quot;&gt;Chapter 3 Diagnostics and Remedial Measures&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-4-simultaneous-inferences-and-other-topics-in-regression-analysis&quot; id=&quot;markdown-toc-chapter-4-simultaneous-inferences-and-other-topics-in-regression-analysis&quot;&gt;Chapter 4 Simultaneous Inferences and Other Topics in Regression Analysis&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-5-matrix-approach-to-simple-linear-regression-analysis&quot; id=&quot;markdown-toc-chapter-5-matrix-approach-to-simple-linear-regression-analysis&quot;&gt;Chapter 5 Matrix Approach to Simple Linear Regression Analysis&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-matrices&quot; id=&quot;markdown-toc-51-matrices&quot;&gt;5.1 Matrices&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-matrix-addition-and-subtraction&quot; id=&quot;markdown-toc-52-matrix-addition-and-subtraction&quot;&gt;5.2 Matrix Addition and Subtraction&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-matrix-multiplication&quot; id=&quot;markdown-toc-53-matrix-multiplication&quot;&gt;5.3 Matrix Multiplication&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#54-special-types-of-matrices&quot; id=&quot;markdown-toc-54-special-types-of-matrices&quot;&gt;5.4 Special Types of Matrices&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#55-linear-dependence-and-rank-of-matrix&quot; id=&quot;markdown-toc-55-linear-dependence-and-rank-of-matrix&quot;&gt;5.5 Linear Dependence and Rank of Matrix&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#56-inverse-of-a-matrix&quot; id=&quot;markdown-toc-56-inverse-of-a-matrix&quot;&gt;5.6 Inverse of a Matrix&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#57-some-basic-results-for-matrics&quot; id=&quot;markdown-toc-57-some-basic-results-for-matrics&quot;&gt;5.7 Some Basic Results for Matrics&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#58-random-vectors-and-matrices&quot; id=&quot;markdown-toc-58-random-vectors-and-matrices&quot;&gt;5.8 Random Vectors and Matrices&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#59-simple-linear-regression-model-in-matrix-terms&quot; id=&quot;markdown-toc-59-simple-linear-regression-model-in-matrix-terms&quot;&gt;5.9 Simple Linear Regression Model in Matrix Terms&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#510-least-squares-estimation-of-regression-parameters&quot; id=&quot;markdown-toc-510-least-squares-estimation-of-regression-parameters&quot;&gt;5.10 Least Squares Estimation of Regression Parameters&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#511-fitted-values-and-residuals&quot; id=&quot;markdown-toc-511-fitted-values-and-residuals&quot;&gt;5.11 Fitted Values and Residuals&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#512-analysis-of-variance-results&quot; id=&quot;markdown-toc-512-analysis-of-variance-results&quot;&gt;5.12 Analysis of Variance Results&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#513-inferences-in-regression-analysis&quot; id=&quot;markdown-toc-513-inferences-in-regression-analysis&quot;&gt;5.13 Inferences in Regression Analysis&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#part-2-multiple-linear-regression&quot; id=&quot;markdown-toc-part-2-multiple-linear-regression&quot;&gt;Part 2 Multiple linear regression&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-6-multiple-regression-i&quot; id=&quot;markdown-toc-chapter-6-multiple-regression-i&quot;&gt;Chapter 6 Multiple Regression I&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-7-multiple-regression-ii&quot; id=&quot;markdown-toc-chapter-7-multiple-regression-ii&quot;&gt;Chapter 7 Multiple Regression II&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-8-regression-models-for-quantitative-and-qualitative-predictors&quot; id=&quot;markdown-toc-chapter-8-regression-models-for-quantitative-and-qualitative-predictors&quot;&gt;Chapter 8 Regression Models for quantitative and qualitative predictors&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-9-building-the-regression-model-i-model-selection-and-validation&quot; id=&quot;markdown-toc-chapter-9-building-the-regression-model-i-model-selection-and-validation&quot;&gt;Chapter 9 Building the regression model I: model selection and validation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-10-building-the-regression-model-ii-diagnostics&quot; id=&quot;markdown-toc-chapter-10-building-the-regression-model-ii-diagnostics&quot;&gt;Chapter 10 Building the regression model II: Diagnostics&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-11-building-the-regression-model-iii-remedial-measures&quot; id=&quot;markdown-toc-chapter-11-building-the-regression-model-iii-remedial-measures&quot;&gt;Chapter 11 Building the regression model III: Remedial Measures&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-12-autocorrelation-in-time-series-data&quot; id=&quot;markdown-toc-chapter-12-autocorrelation-in-time-series-data&quot;&gt;Chapter 12 Autocorrelation in Time Series Data&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#part-3-nonlinear-regression&quot; id=&quot;markdown-toc-part-3-nonlinear-regression&quot;&gt;Part 3 Nonlinear regression&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-13-introduction-to-nonlinear-regression-and-neural-networks&quot; id=&quot;markdown-toc-chapter-13-introduction-to-nonlinear-regression-and-neural-networks&quot;&gt;Chapter 13 Introduction to Nonlinear Regression and Neural Networks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#chapter-14-logistic-regression-possion-regression-and-generalized-linear-regression&quot; id=&quot;markdown-toc-chapter-14-logistic-regression-possion-regression-and-generalized-linear-regression&quot;&gt;Chapter 14 Logistic Regression, Possion Regression, and Generalized Linear Regression&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;part-1-simple-linear-regression&quot;&gt;Part 1 Simple linear regression&lt;/h2&gt;

&lt;h3 id=&quot;chapter-1-linear-regression-with-one-predictor-variable&quot;&gt;Chapter 1 Linear regression with one predictor variable&lt;/h3&gt;

&lt;h4 id=&quot;11-relations-between-variables&quot;&gt;1.1 Relations between variables&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;relation
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;Function relation&lt;/em&gt;: Y = f(X), e.g. total cost = the number of products * cost per product&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;Statistical relation&lt;/em&gt;: not a perfect one, e.g. performance for 10 employees at midyear and year-end&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;variable
    &lt;ul&gt;
      &lt;li&gt;X: &lt;em&gt;independent/explanatory/predictor variable&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;Y: &lt;em&gt;dependent/response variable&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;plot
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;scatter diagram/plot&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;each point represents a &lt;em&gt;trial&lt;/em&gt; or a &lt;em&gt;case&lt;/em&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;12-regression-models-and-their-uses&quot;&gt;1.2 Regression Models and Their Uses&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;History
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Francis_Galton&quot;&gt;Sir Francis Galton&lt;/a&gt; in the latter part of 19th century&lt;/li&gt;
      &lt;li&gt;relation between heights of parents and children&lt;/li&gt;
      &lt;li&gt;regression to the mean&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Basic Concepts
    &lt;ul&gt;
      &lt;li&gt;A regression model&lt;/li&gt;
      &lt;li&gt;two characters:
        &lt;ul&gt;
          &lt;li&gt;there is a probability distribution of Y for each level of X&lt;/li&gt;
          &lt;li&gt;The means of these probability distribution vary in some systematic fashion with X&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;em&gt;regression function&lt;/em&gt;: the systematic relationship
        &lt;ul&gt;
          &lt;li&gt;&lt;em&gt;linear&lt;/em&gt;, &lt;em&gt;curvilinear&lt;/em&gt;, etc.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;em&gt;regression curve&lt;/em&gt;: the graph of the regression function&lt;/li&gt;
      &lt;li&gt;probability distributions: &lt;em&gt;symmetrical&lt;/em&gt;, &lt;em&gt;skewed&lt;/em&gt; etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Regression models with more than one predictor variable&lt;/li&gt;
  &lt;li&gt;Construction of Regression Models
    &lt;ul&gt;
      &lt;li&gt;Selection of predictor variables&lt;/li&gt;
      &lt;li&gt;Functional form of regression relation&lt;/li&gt;
      &lt;li&gt;Scope of model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Uses of regression analysis
    &lt;ul&gt;
      &lt;li&gt;description&lt;/li&gt;
      &lt;li&gt;control&lt;/li&gt;
      &lt;li&gt;prediction&lt;/li&gt;
      &lt;li&gt;overlap in practice&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Regeression and causality&lt;/li&gt;
  &lt;li&gt;Use of Computers&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;13-simple-linear-regression-model-with-distribution-of-error-terms-unspecified&quot;&gt;1.3 Simple linear regression model with distribution of error terms unspecified&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Formal statement of model&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i} = \beta_{0} + \beta_{1}X_{i} + \varepsilon_{i}&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$Y_{i}$ is the value of th response variable in the ith trail&lt;/li&gt;
  &lt;li&gt;$\beta_{0}\text{ and }\beta_{1}$ are paramters&lt;/li&gt;
  &lt;li&gt;$X_{i}$ is a known constant, namely, the value of the predictor variable in the ith trial&lt;/li&gt;
  &lt;li&gt;$\varepsilon_{i}$ is a random error term
    &lt;ul&gt;
      &lt;li&gt;mean $E(\varepsilon_{i}) = 0$&lt;/li&gt;
      &lt;li&gt;variance $\sigma^{2}(\varepsilon_{i}) = \sigma^{2}$&lt;/li&gt;
      &lt;li&gt;covariance $\sigma(\varepsilon_{i}, \varepsilon_{j}) = 0$, for all i, j; $i \neq j$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Important features of model&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;$Y_{i}$ contains two components: the constant term $\beta_{0} + \beta_{1}X_{i}$ and the random term $\varepsilon_{i}$. Hence, $Y_{i}$ is a random variable&lt;/li&gt;
  &lt;li&gt;Since $E(\varepsilon_{i}) = 0$, $E(Y_{i}) = E(\beta_{0} + \beta_{1}X_{i} + \varepsilon_{i}) = \beta_{0} + \beta_{1}X_{i} + E(\varepsilon_{i}) = \beta_{0} + \beta_{1}X_{i}$&lt;/li&gt;
  &lt;li&gt;The response $Y_{i}$ in the ith trail exceeds or falls short of the value of the regssion fucntion by the error term amount $\varepsilon_{i}$&lt;/li&gt;
  &lt;li&gt;The erorr term $\varepsilon_{i}$ are assumed to have constant variance $\sigma^{2}$ and $\sigma^{2}(Y_{i}) = \sigma^{2}$&lt;/li&gt;
  &lt;li&gt;The error terms are assumed to be uncorrelated, so are the responses $Y_{i}$ and $Y_{j}$&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Meaning of regression paramters
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;regrssion coefficients&lt;/em&gt;: the paramters $\beta_{0}\text{ and }\beta_{1}$&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;the slope of the regression line&lt;/em&gt;: $\beta_{1}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Alternative versions of regression model&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i} = \beta_{0}X_{0} + \beta_{1}X_{i} + \varepsilon_{i}\text{, where }X_{0} \equiv 1&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i} = \beta_{0}^{*} + \beta_{1}(X_{i} - \bar{X}) + \varepsilon_{i}\text{, where }\beta_{0}^{*} = \beta_{0} + \beta_{1}\bar{X}&lt;/script&gt;

&lt;h4 id=&quot;14-data-for-regression-analysis&quot;&gt;1.4 Data for regression analysis&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Observational Data&lt;/li&gt;
  &lt;li&gt;Eperimental Data
    &lt;ul&gt;
      &lt;li&gt;treatment&lt;/li&gt;
      &lt;li&gt;experimental units&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Completely randomized design&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;15-overview-of-steps-in-regression-analysis&quot;&gt;1.5 Overview of steps in regression analysis&lt;/h4&gt;

&lt;h4 id=&quot;16-estimation-of-regression-function&quot;&gt;1.6 Estimation of regression function&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Methods of Least Squares
    &lt;ul&gt;
      &lt;li&gt;To find estimates $b_{0}$ and $b_{1}$ for $\beta_{0}$ and $\beta_{1}$, respectively, for which Q is a minimum, where $Q = \displaystyle\sum_{i=1}^{n}(Y_{i} - \beta_{0} - \beta_{1}X_{i})^2$.&lt;/li&gt;
      &lt;li&gt;Least Squares Estimators $b_{0}$ and $b_{1}$ can be found in two ways:
        &lt;ul&gt;
          &lt;li&gt;numerical search procedures&lt;/li&gt;
          &lt;li&gt;analytical procedures&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{1} = \frac{\sum(X_{i} - \bar{X})(Y_{i} - \bar{Y})}{\sum(X_{i} - \bar{X})^2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{0} = \frac{1}{n}(\sum Y_{i} - b_{1} \sum X_{i}) = \bar{Y} - b_{1}\bar{X}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Proof&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The paritial derivatives are&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial Q}{\partial\beta_{0}} = -2\sum(Y_{i} - \beta_{0} - \beta_{1}X_{i})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial Q}{\partial\beta_{1}} = -2\sum X_{i}(Y_{i} - \beta_{0} - \beta_{1}X_{i})&lt;/script&gt;

&lt;p&gt;We set them equal to zero, using $b_{0}$ and $b_{1}$ to denote the particular values of $b_{0}$ and $b_{1}$ that minimize Q:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;-2\sum(Y_{i} - \beta_{0} - \beta_{1}X_{i}) = 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;-2\sum X_{i}(Y_{i} - \beta_{0} - \beta_{1}X_{i}) = 0&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Proerties of Least Squares Estimators&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Guass-Markov theorem:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Under the conditions of regression model, the least squares estimators b0 and b1 are unbiased and have minimum variance among all unbiased linear estimators&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Point Esitmation of Mean Response
    &lt;ul&gt;
      &lt;li&gt;estimate the regression function as follows:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{Y} = b_{0} + b_{1}X&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;Residuals
    &lt;ul&gt;
      &lt;li&gt;residual: the differenc between the observed value $Y_{i}$ and the corresponding fitted value $\hat{Y_{i}}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_{i} = Y_{i} - \hat{Y}_{i}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Properties of Fitted Regression Line
    &lt;ul&gt;
      &lt;li&gt;$\sum e_{i} = 0$&lt;/li&gt;
      &lt;li&gt;$\sum e_{i}^{2}$ is a minimum&lt;/li&gt;
      &lt;li&gt;$\sum Y_{i} = \sum \hat{Y}_{i}$&lt;/li&gt;
      &lt;li&gt;$\sum X_{i} e_{i} = 0 $&lt;/li&gt;
      &lt;li&gt;$\sum \hat{Y}_{i}$e&lt;sub&gt;i&lt;/sub&gt; = 0&lt;/li&gt;
      &lt;li&gt;the regression line always goes through the point $(\bar{X}, \bar{Y})$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;17-estimation-of-erro-terms-variance-sigma2&quot;&gt;1.7 Estimation of Erro Terms Variance $\sigma^{2}$&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Point Estimator of $\sigma^{2}$
    &lt;ul&gt;
      &lt;li&gt;Single population
        &lt;ul&gt;
          &lt;li&gt;sum of squares: $\displaystyle\sum_{i=1}^{n}(Y_{i}-\bar{Y})^2$&lt;/li&gt;
          &lt;li&gt;degrees of freedom (df): n - 1, because one degree of freedom is lost by using $\bar{Y}$ as an estimate of the unknown population mean $\mu$&lt;/li&gt;
          &lt;li&gt;sample variance/mean square: $s^2 = \frac{\displaystyle\sum(Y_{i}-\bar{Y})^2}{n-1}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Regression model
        &lt;ul&gt;
          &lt;li&gt;deviation/residual: $Y_{i} - \hat{Y}_{i}$ = e&lt;sub&gt;i&lt;/sub&gt;&lt;/li&gt;
          &lt;li&gt;error/residual sum of squares:
            &lt;ul&gt;
              &lt;li&gt;$SSE = \displaystyle\sum_{i=1}^{n}(Y_{i} - \hat{Y}_{i})^{2}$&lt;/li&gt;
              &lt;li&gt;$SSE = \displaystyle\sum_{i=1}^{n}e_{i}^{2}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;degrees of freedom: n - 2, because two degrees of freedom are lost due to estimating $\beta_{0}$ and $\beta_{1}$ to get $\hat{Y}_{i}$&lt;/li&gt;
          &lt;li&gt;MSE (error/residual mean square): $s^{2} = MSE = \frac{SSE}{n-2}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;18-normal-error-regression-model&quot;&gt;1.8 Normal Error Regression Model&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Model
    &lt;ul&gt;
      &lt;li&gt;same with simple linear regression model&lt;/li&gt;
      &lt;li&gt;except it assumes that the error $\varepsilon_{i}$ are normally distributed&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Estimation of Parameters by Method of Maximum Likelihood&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Method of maximum likelihood chooses as estimates those values of the parameters that are most consistent with the sample data.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;A normal distribution with SD = 10, mean is unknown
A random of sample n = 3 yields the results 250, 265 and 259
The likelihood value (L) is the product of the densities of the normal distribution

If we assue μ = 230, L(μ = 230) = 0.279*10E-9 
R code: prod(dnorm(c(250,265,259), 230, 10))
If we assue μ = 259, L(μ = 259) = 0.0000354
R code: prod(dnorm(c(250,265,259), 259, 10))

So, L(μ = 259) &amp;gt; L(μ = 230)

The method of maximum likelihood is to estimate prarametes to get maximum L.
It can be shown that for a normal population,
the maximum likelihood estimator of μ is the smaple mean
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Fro regression model, the likelihood function for n observations is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\beta_{0}, \beta_{1}, \sigma^{2}) = \displaystyle\Pi_{i=1}^{n}\frac{1}{(2\pi\sigma^{2})^{1/2}}exp[-\frac{1}{2\sigma^{2}}(Y_{i} - \beta_{0} - \beta_{1}X_{i})^{2}]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\beta_{0}, \beta_{1}, \sigma^{2}) = \frac{1}{(2\pi\sigma^{2})^{1/2}}exp[-\frac{1}{2\sigma^{2}}\displaystyle\sum_{i=1}^{n}(Y_{i} - \beta_{0} - \beta_{1}X_{i})^{2}]&lt;/script&gt;

&lt;h3 id=&quot;chapter-2-inferences-in-regression-and-correlation-analysis&quot;&gt;Chapter 2 Inferences in Regression and Correlation Analysis&lt;/h3&gt;

&lt;h4 id=&quot;21-inferences-concerning-beta_1&quot;&gt;2.1 Inferences Concerning $\beta_{1}$&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling Distribution of b1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The sampling distribution of b1 refers to the different values of b1 that would be obtained with repeated sampling when the levels of the predictor variable X are held constant from sample to sample.&lt;/p&gt;

&lt;p&gt;For normal error regression model, the sample distributon of b1 is &lt;strong&gt;normal&lt;/strong&gt;, with mean and variance:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(b1) = \beta_{1}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma^{2}(b1) = \frac{\sigma^{2}}{\sum(X_{i} - \bar{X})^{2}}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Proof&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;b1 as linear combination of the Yi&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;b1 = \sum k_{i}Y_{i}\text{where }k_{i} = \frac{X_{i} - \bar{X}}{\sum(X_{i} - \bar{X})^{2}}&lt;/script&gt;
 &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nomaily&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The $Y_{i}$ are independently, normally distributed, so b1 are normally distributed.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mean&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(b_{1}) = E(\sum k_{i}Y_{i}) = \sum k_{i}E(Y_{i}) = \sum k_{i}(\beta_{0} + \beta_{1}X_{i}) = \beta_{1}&lt;/script&gt;

&lt;p&gt;hint:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum k_{i} = 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum k_{i}X_{i} = 1&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Variance&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma^{2}(b_{1}) = \sigma^{2}(\sum k_{i}Y_{i}) = \sum k_{i}^{2}\sigma^{2}(Y_{i}) = \sum k_{i}^{2}\sigma^{2} = \sigma^{2}\frac{1}{\sum (X_{i} - \bar{X})^{2}}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Estimated Variance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Replace the paramter $\sigma^{2}$ with MSE:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{2}(b_{1}) = \frac{MSE}{\sum(X_{i} - \bar{X})^{2}}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling Distribution of $(b_{1} - \beta_{1})/s(b_{1})$&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(b_{1} - \beta_{1})/\sigma(b_{1}) \sim N(0,1)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(b_{1} - \beta_{1})/s(b_{1}) \sim t(n-2)&lt;/script&gt;

&lt;p&gt;When a statistic is standardized but the denominator is an estimated standard deviation rather than the true standard deviation, it is called a studentized statistic.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Comment&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SSE/\sigma^{2} \sim \chi^{2}(n - 2)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(b_{1} - \beta_{1})/s(b_{1}) \sim \frac{z}{\sqrt{\frac{\chi^2(n-2)}{n-2}}} = t(n-2)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Confidence Interval for $\beta_{1}$&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{1} \pm t(1-\alpha/2; n-2)s(b_{1})\text{ where }\alpha\text{ is significance level}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Tests concerning $\beta_{1}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since $(b_{1} - \beta_{1})/s(b_{1})$ is ditributed as t with n - 2degrees of freedom, tests concerning $\beta_{1}$ can be set up in ordinary fashion using the t distribution.&lt;/p&gt;

&lt;h4 id=&quot;22-inferences-concerning-beta_0&quot;&gt;2.2 Inferences Concerning $\beta_{0}$&lt;/h4&gt;

&lt;p&gt;The sampling distribution of $\beta_{0}$ is normal, with mean and variance:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(b_{0}) = \beta_{0}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma^{2}(b_{0}) = \sigma^{2}[\frac{1}{n} + \frac{\bar{X}^{2}}{\sum (X_{i} - \bar{X})^{2}}]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{2}(b_{0}) = MSE[\frac{1}{n} + \frac{\bar{X}^{2}}{\sum (X_{i} - \bar{X})^{2}}]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{b_{0} - \beta_{0}}{s(b_{0})} \sim t(n-2)&lt;/script&gt;

&lt;h4 id=&quot;23-some-considerations-on-making-inferences-concerning-beta_0-and-beta_1&quot;&gt;2.3 Some Considerations on Making Inferences Concerning $\beta_{0}$ and $\beta_{1}$&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Effects of Departures from Normality&lt;/li&gt;
  &lt;li&gt;Interpretation of Confidence Coefficient and Risks of Errors&lt;/li&gt;
  &lt;li&gt;Spacing of the X levels&lt;/li&gt;
  &lt;li&gt;Power of Tests&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The power of this test is the probability that the decision rule will lead to conclusion $H_{a}$ when $H_{a}$ in fact holds. Specifically, the power is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Power = P(|t^{*}| &gt; t(1-\alpha/2;n-2)|\delta)&lt;/script&gt;

&lt;p&gt;where,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$H_{0}: \beta_{1} = \beta_{10}$; $H_{a}: \beta_{1} \neq \beta_{10}$&lt;/li&gt;
  &lt;li&gt;$t^{*} = \frac{b_{1} - \beta_{10}}{s(b_{1})}$&lt;/li&gt;
  &lt;li&gt;$\delta$ is the &lt;strong&gt;noncentrality measure&lt;/strong&gt;, a measure of how far the true value of $\beta_{1}$ is from $\beta_{10}$. $\delta = \frac{\mid\beta_{1} - \beta_{10}\mid}{\sigma(b_{1})}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;24-interval-estimation-of-ey_h&quot;&gt;2.4 Interval Estimation of $E(Y_{h})$&lt;/h4&gt;

&lt;p&gt;The mean response when $X = X_{h}$ is denoted by $E(Y_{h})$. The $E(Y_{h})$ point estimator $\hat{Y}_{h}$ :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{Y}_{h} = b_{0} + b_{1}X_{h}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling Distribution of $\hat{Y}_{h}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For normal error regression model, the sampling distribution of $\hat{Y}_{h}$ is normal, with mean and variance:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(\hat{Y}_{h}) = E(Y_{h})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma^{2}(\hat{Y}_{h}) = \sigma^{2}[\frac{1}{n} + \frac{(X_{h} - \bar{X})^2}{\sum(X_{i} - \bar{X})^{2}}]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{2}(\hat{Y}_{h}) = MSE[\frac{1}{n} + \frac{(X_{h} - \bar{X})^{2}}{\sum (X_{i} - \bar{X})^{2}}]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\hat{Y}_{h} - E(Y_{h})}{s(\hat{Y}_{h})} \sim t(n-2)&lt;/script&gt;

&lt;h4 id=&quot;25-prediction-of-new-observation&quot;&gt;2.5 Prediction of New Observation&lt;/h4&gt;

&lt;p&gt;We denotethe level of X for the new trial as $X_{h}$ and the new observation on Y as $Y_{h(new)}$.&lt;/p&gt;

&lt;p&gt;In the former case, the estimation of $E(Y_{h})$ is the &lt;strong&gt;mean&lt;/strong&gt; of the distribution of Y; in the present case, we predict an &lt;strong&gt;individual outcome&lt;/strong&gt; draw from the distribution of Y.&lt;/p&gt;

&lt;p&gt;Hence, two components of $\sigma(pred)$:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The variance of the distribution of Y at $X = X_{h}$, namely $\sigma^{2}$&lt;/li&gt;
  &lt;li&gt;The variance of the sampling distribution of $\hat{Y}&lt;em&gt;{h}$, namely $\sigma^{2}(\hat{Y}&lt;/em&gt;{h})$&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma^{2}(pred) = \sigma^{2}(Y_{h(new)} - \hat{Y}_{h}) = \sigma^{2} + \sigma^{2}(\hat{Y}_{h})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s^{2}(pred) = MSE[1 + \frac{1}{n} + \frac{(X_{h} - \bar{X})^{2}}{\sum (X_{i} - \bar{X})^{2}}]&lt;/script&gt;

&lt;h4 id=&quot;26-confidence-band-for-regression-line&quot;&gt;2.6 Confidence Band for Regression Line&lt;/h4&gt;

&lt;p&gt;To obtain a confidence band for the entire for the entire regression line $E(Y) = \beta_{0} + \beta_{1}X$.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Working-Hotellling&lt;/strong&gt; 1 - $\alpha$ confidence band:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{Y}_{h} \pm Ws(\hat{Y}_{h})&lt;/script&gt;

&lt;p&gt;where,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W^{2} = 2F(1-\alpha; 2, n-2)&lt;/script&gt;

&lt;p&gt;Since, we are doing all values of $X_{h}$ at once, it will be wider at each $X_{h}$ than CIs for individual $X_{h}$.&lt;/p&gt;

&lt;h4 id=&quot;27-analysis-of-variance-approach&quot;&gt;2.7 Analysis of Variance Approach&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Partitioning of Total Sum of Squares&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i} - \bar{Y} = \hat{Y}_{i} - \bar{Y} + Y_{i} - \hat{Y}_{i}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum (Y_{i} - \bar{Y})^{2} = \sum (\hat{Y}_{i} - \bar{Y})^{2} + \sum (Y_{i} - \hat{Y}_{i})^{2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SSTO = SSR + SSE&lt;/script&gt;

&lt;p&gt;SSTO stands for &lt;strong&gt;total sum of squares&lt;/strong&gt;, SSE stands for &lt;strong&gt;error sum of squares&lt;/strong&gt; and SSR stands for &lt;strong&gt;regression sum of squares&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Breakdown of Degrees of Freedom&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;n - 1 = 1 + (n - 2)&lt;/script&gt;

&lt;p&gt;We have n-1 degrees of freedom associated with SSTO. SSE has n-2 degrees of freedom and SSR has 1 degree of freedom.&lt;/p&gt;

&lt;h4 id=&quot;28-general-linear-test-approach&quot;&gt;2.8 General Linear Test Approach&lt;/h4&gt;

&lt;h4 id=&quot;29-descriptive-measures-of-linear-association-between-x-and-y&quot;&gt;2.9 Descriptive Measures of Linear Association between X and Y&lt;/h4&gt;

&lt;h4 id=&quot;210-considerations-in-applying-regression-analysis&quot;&gt;2.10 Considerations in Applying Regression Analysis&lt;/h4&gt;

&lt;h4 id=&quot;211-normal-correlation-models&quot;&gt;2.11 Normal Correlation Models&lt;/h4&gt;

&lt;h3 id=&quot;chapter-3-diagnostics-and-remedial-measures&quot;&gt;Chapter 3 Diagnostics and Remedial Measures&lt;/h3&gt;

&lt;h3 id=&quot;chapter-4-simultaneous-inferences-and-other-topics-in-regression-analysis&quot;&gt;Chapter 4 Simultaneous Inferences and Other Topics in Regression Analysis&lt;/h3&gt;

&lt;h3 id=&quot;chapter-5-matrix-approach-to-simple-linear-regression-analysis&quot;&gt;Chapter 5 Matrix Approach to Simple Linear Regression Analysis&lt;/h3&gt;

&lt;h4 id=&quot;51-matrices&quot;&gt;5.1 Matrices&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Definition
    &lt;ul&gt;
      &lt;li&gt;matrix&lt;/li&gt;
      &lt;li&gt;dlements&lt;/li&gt;
      &lt;li&gt;dimension&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Notation: a boldface symbol, such as &lt;strong&gt;A&lt;/strong&gt;, &lt;strong&gt;X&lt;/strong&gt; or &lt;strong&gt;Z&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Square Matrix: the number of rows equals the number of columns&lt;/li&gt;
  &lt;li&gt;Vector
    &lt;ul&gt;
      &lt;li&gt;column vector/vector: only one column matrix&lt;/li&gt;
      &lt;li&gt;row vector&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Transpose: &lt;strong&gt;A’&lt;/strong&gt; (A prime) is the transpose of a matrix &lt;strong&gt;A&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Equality of Matrices: same dimension and all same corresponding elements&lt;/li&gt;
  &lt;li&gt;design matrix&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;52-matrix-addition-and-subtraction&quot;&gt;5.2 Matrix Addition and Subtraction&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;same dimension&lt;/li&gt;
  &lt;li&gt;the sum or difference of the corresponding elements of the two matrixs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;A&lt;/strong&gt; + &lt;strong&gt;B&lt;/strong&gt; = &lt;strong&gt;B&lt;/strong&gt; + &lt;strong&gt;A&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;53-matrix-multiplication&quot;&gt;5.3 Matrix Multiplication&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Multiplication of a Matrix by a &lt;strong&gt;scalar&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;a scalar is an ordinary number or a symbol representing a number&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Multiplication of a Matrix by a Matrix
    &lt;ul&gt;
      &lt;li&gt;the product &lt;strong&gt;AB&lt;/strong&gt;, we say that &lt;strong&gt;A&lt;/strong&gt; is postmultiplied by &lt;strong&gt;B&lt;/strong&gt; or &lt;strong&gt;B&lt;/strong&gt; is premultiplied by &lt;strong&gt;A&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;$AB \neq BA$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In general, if &lt;strong&gt;A&lt;/strong&gt; has dimension r * c and &lt;strong&gt;B&lt;/strong&gt; has dimension c * s, the product &lt;strong&gt;AB&lt;/strong&gt; is a matrix of dimension r * s, which is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;AB_{r \times s} = \begin{bmatrix}\sum_{k=1}^{c} a_{ik}b_{kj}\end{bmatrix}\text{, where }i=1,...,r;j=1,...,s&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Regression Examples&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
Y'Y_{1 \times 1} = \begin{bmatrix} Y_{1} &amp; Y_{2} &amp; ... &amp; Y_{n} \end{bmatrix}\begin{bmatrix}Y_{1} \\ Y_{2} \\ ... \\ Y_{n} \end{bmatrix} =  Y_{1}^{2} + Y_{2}^{2} + ... + Y_{n}^{2} = \sum Y_{i}^{2} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
X'X_{2 \times 2} = \begin{bmatrix} 1 &amp; 1 &amp; ... &amp; 1 \\ X_{1} &amp; X_{2} &amp; ... &amp; X_{n} \end{bmatrix}\begin{bmatrix} 1 &amp; X_{1} \\ 1 &amp; X_{2} \\ ... \\ 1 &amp; X_{n} \end{bmatrix} =  \begin{bmatrix} n &amp; \sum X_{i} \\ \sum X_{i} &amp; \sum X_{i}^{2} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
X'Y_{2 \times 1} = \begin{bmatrix} 1 &amp; 1 &amp; ... &amp; 1 \\ X_{1} &amp; X_{2} &amp; ... &amp; X_{n} \end{bmatrix}\begin{bmatrix} Y_{1} \\ Y_{2} \\ ... \\ Y_{n} \end{bmatrix} =  \begin{bmatrix} \sum Y_{i} \\ \sum X_{i}Y_{i} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;54-special-types-of-matrices&quot;&gt;5.4 Special Types of Matrices&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Symmetric Matrix: &lt;strong&gt;A&lt;/strong&gt; = &lt;strong&gt;A’&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Symmetric matrix is necessarily square&lt;/li&gt;
      &lt;li&gt;premultiply a matrix by its transpose, say &lt;strong&gt;X’X&lt;/strong&gt; is symmetric&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Diagonal Matrix: off-diagonal elements are all zeros&lt;/li&gt;
  &lt;li&gt;Identity Matrix, denoted by &lt;strong&gt;I&lt;/strong&gt;: a diagonal matrix whose elements on the main diagonal are all 1s.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;AI&lt;/strong&gt; = &lt;strong&gt;IA&lt;/strong&gt; = &lt;strong&gt;A&lt;/strong&gt;, $A, I \in \mathbb{R}^{r \times r}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Scalar Marix: a diagonal matrix whose main-diagonal elements are the same, can be expressed as k&lt;strong&gt;I&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Vector and matrix with all elements unity
    &lt;ul&gt;
      &lt;li&gt;a column vector with all elements 1 will be denoted by &lt;strong&gt;1&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;a square matrix with all elements 1 will be denoted by &lt;strong&gt;J&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;1’1&lt;/strong&gt; = n&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;11’&lt;/strong&gt; = &lt;strong&gt;J&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Zero Vector: a vector containing only zeros, denoted by &lt;strong&gt;0&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;55-linear-dependence-and-rank-of-matrix&quot;&gt;5.5 Linear Dependence and Rank of Matrix&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Linear dependence&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We define the set of c column vectors $C_{1}, …, C_{c}$ in an r $\times$ c matrix to be &lt;strong&gt;linearly dependent&lt;/strong&gt; if one vector can be expressed as a linear combination of others. If no vector in the set can be so expressed, we define the set of vectors to be &lt;strong&gt;linearly independent&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In a more general, when c scalars $k_{1},…,k_{c}$, not all zero, can be found such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;k_{1}\mathbf{C_{1}} + k_{2}\mathbf{C_{2}} + ... + k_{c}\mathbf{C_{c}} = \mathbf{0}&lt;/script&gt;

&lt;p&gt;where &lt;strong&gt;0&lt;/strong&gt; denotes the zero column vector, &lt;strong&gt;the c column vectors&lt;/strong&gt; are &lt;strong&gt;linearly dependent&lt;/strong&gt;. If the only set of scalars for which the equality holds is $k_{1} = k_{2} = … = k_{c} = 0$, &lt;strong&gt;the set of c column vectors&lt;/strong&gt; is &lt;strong&gt;linearly independent&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rank of Matrix: the maximum number of linearly independent columns in the matrix
    &lt;ul&gt;
      &lt;li&gt;the rank of r $\times$ c matrix cannot exceed min(r, c)&lt;/li&gt;
      &lt;li&gt;When a matrix is the product of two matrixs, its rank cannot exceed the smaller of the two ranks for the matrices being multiplied.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;56-inverse-of-a-matrix&quot;&gt;5.6 Inverse of a Matrix&lt;/h4&gt;

&lt;p&gt;The inverse of a matrix $\mathbf{A}$ is another matrix, denoted by $\mathbf{A^{-1}}$, such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{A}^{-1}\mathbf{A} = \mathbf{AA}^{-1} = \mathbf{I}&lt;/script&gt;

&lt;p&gt;where &lt;strong&gt;I&lt;/strong&gt; is the identity matrix.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the inverse of a matrix is defined only for square matrix&lt;/li&gt;
  &lt;li&gt;many square matrix do not have inverse&lt;/li&gt;
  &lt;li&gt;the inverse of a square matrix, if exits, is unique&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finding the inverse&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An inverse of a square $r \times r$ matrix exists if the rank of the matrix is r. Such a matrix is said to be &lt;strong&gt;nonsingular&lt;/strong&gt; or of &lt;strong&gt;full rank&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;An $r \times r$ matrix with rank less than r is said to be &lt;strong&gt;singular&lt;/strong&gt; or &lt;strong&gt;not of full rank&lt;/strong&gt;, and does not have an inverse.&lt;/li&gt;
  &lt;li&gt;The inverse of an $r \times r$ matrix of full rank also has rank r.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathbf{A}_{2 \times 2} = \begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathbf{A}_{2 \times 2}^{-1} = \begin{bmatrix} \frac{d}{D} &amp; \frac{-b}{D} \\ \frac{-c}{D} &amp; \frac{a}{D} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D = ad - bc&lt;/script&gt;

&lt;p&gt;D is called the determinant of the matrix &lt;strong&gt;A&lt;/strong&gt;. If &lt;strong&gt;A&lt;/strong&gt; were singular, its determinant would equal zero and no inverse of A would exist.&lt;/p&gt;

&lt;p&gt;Regression Example&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathbf{X}'\mathbf{X}_{2 \times 2} = \begin{bmatrix} n &amp; \sum X_{i} \\ \sum X_{i} &amp; \sum X_{i}^{2} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a = n, b = c = \sum{X_{i}}, d = \sum{X_{i}^{2}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D = n\sum{X_{i}^{2}} - (\sum{X_{i}})^{2} = n\sum{(X_{i} - \bar{X})}^{2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
(\mathbf{X}'\mathbf{X})_{2 \times 2}^{-1} = \begin{bmatrix} \frac{1}{n} + \frac{\bar{X}^2}{\sum(X_{i} - \bar{X})^{2}} &amp; \frac{-\bar{X}}{\sum{(X_{i} - \bar{X})^2}} \\ \frac{-\bar{X}}{\sum{(X_{i} - \bar{X})^2}} &amp; \frac{1}{\sum{(X_{i} - \bar{X})^2}} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;57-some-basic-results-for-matrics&quot;&gt;5.7 Some Basic Results for Matrics&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;A + B = B + A&lt;/li&gt;
  &lt;li&gt;(A + B) + C = A + (B + C)&lt;/li&gt;
  &lt;li&gt;(AB)C = A(BC)&lt;/li&gt;
  &lt;li&gt;C(A + B) = CA + CB&lt;/li&gt;
  &lt;li&gt;k(A + B) = kA + kB&lt;/li&gt;
  &lt;li&gt;(A’)’ = A&lt;/li&gt;
  &lt;li&gt;(A + B)’ = A’ + B’&lt;/li&gt;
  &lt;li&gt;(AB)’ = B’A’&lt;/li&gt;
  &lt;li&gt;(ABC)’ = C’B’A’&lt;/li&gt;
  &lt;li&gt;$(AB)^{-1} = B^{-1}A^{-1}$&lt;/li&gt;
  &lt;li&gt;$(ABC)^{-1} = C^{-1}B^{-1}A^{-1}$&lt;/li&gt;
  &lt;li&gt;$(A^{-1})^{-1} = A$&lt;/li&gt;
  &lt;li&gt;$(A’)^{-1} = (A^{-1})’$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;58-random-vectors-and-matrices&quot;&gt;5.8 Random Vectors and Matrices&lt;/h4&gt;

&lt;h4 id=&quot;59-simple-linear-regression-model-in-matrix-terms&quot;&gt;5.9 Simple Linear Regression Model in Matrix Terms&lt;/h4&gt;

&lt;h4 id=&quot;510-least-squares-estimation-of-regression-parameters&quot;&gt;5.10 Least Squares Estimation of Regression Parameters&lt;/h4&gt;

&lt;h4 id=&quot;511-fitted-values-and-residuals&quot;&gt;5.11 Fitted Values and Residuals&lt;/h4&gt;

&lt;h4 id=&quot;512-analysis-of-variance-results&quot;&gt;5.12 Analysis of Variance Results&lt;/h4&gt;

&lt;h4 id=&quot;513-inferences-in-regression-analysis&quot;&gt;5.13 Inferences in Regression Analysis&lt;/h4&gt;

&lt;h2 id=&quot;part-2-multiple-linear-regression&quot;&gt;Part 2 Multiple linear regression&lt;/h2&gt;

&lt;h3 id=&quot;chapter-6-multiple-regression-i&quot;&gt;Chapter 6 Multiple Regression I&lt;/h3&gt;

&lt;h3 id=&quot;chapter-7-multiple-regression-ii&quot;&gt;Chapter 7 Multiple Regression II&lt;/h3&gt;

&lt;h3 id=&quot;chapter-8-regression-models-for-quantitative-and-qualitative-predictors&quot;&gt;Chapter 8 Regression Models for quantitative and qualitative predictors&lt;/h3&gt;

&lt;h3 id=&quot;chapter-9-building-the-regression-model-i-model-selection-and-validation&quot;&gt;Chapter 9 Building the regression model I: model selection and validation&lt;/h3&gt;

&lt;h3 id=&quot;chapter-10-building-the-regression-model-ii-diagnostics&quot;&gt;Chapter 10 Building the regression model II: Diagnostics&lt;/h3&gt;

&lt;h3 id=&quot;chapter-11-building-the-regression-model-iii-remedial-measures&quot;&gt;Chapter 11 Building the regression model III: Remedial Measures&lt;/h3&gt;

&lt;h3 id=&quot;chapter-12-autocorrelation-in-time-series-data&quot;&gt;Chapter 12 Autocorrelation in Time Series Data&lt;/h3&gt;

&lt;h2 id=&quot;part-3-nonlinear-regression&quot;&gt;Part 3 Nonlinear regression&lt;/h2&gt;

&lt;h3 id=&quot;chapter-13-introduction-to-nonlinear-regression-and-neural-networks&quot;&gt;Chapter 13 Introduction to Nonlinear Regression and Neural Networks&lt;/h3&gt;

&lt;h3 id=&quot;chapter-14-logistic-regression-possion-regression-and-generalized-linear-regression&quot;&gt;Chapter 14 Logistic Regression, Possion Regression, and Generalized Linear Regression&lt;/h3&gt;
</description>
        <pubDate>Tue, 20 Jun 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/06/20/Linear_Regression.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/06/20/Linear_Regression.html</guid>
        
        <category>statistics</category>
        
        
      </item>
    
      <item>
        <title>HWE and LD</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle&quot;&gt;Hardy-Weinberg equilibrium&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Linkage_disequilibrium&quot;&gt;Linkage disequilibrium&lt;/a&gt; are two basic concepts in &lt;a href=&quot;https://en.wikipedia.org/wiki/Population_genetics&quot;&gt;population genetics&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;defination&quot;&gt;Defination&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Hardy-Weinberg Equilibrium (HWE): &lt;strong&gt;allele and genotype frequencies&lt;/strong&gt; in a population will remain constant &lt;strong&gt;from generation to generation&lt;/strong&gt; in the absence of other evolutionary influences.&lt;/li&gt;
  &lt;li&gt;Linkage Disequilibrium (LD): the non-random association of &lt;strong&gt;alleles at different loci&lt;/strong&gt; in a given population.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So HWE is about the allele and genotype frequencies in one locus, but LD is about alleles at different loci.&lt;/p&gt;

&lt;h3 id=&quot;hardy-weinberg-equilibrium&quot;&gt;Hardy-Weinberg Equilibrium&lt;/h3&gt;

&lt;h4 id=&quot;from-genotype-to-allele-frequencies&quot;&gt;From Genotype to Allele frequencies&lt;/h4&gt;

&lt;p&gt;For $n_{AA}, n_{Aa}, n_{aa}$ is the count of genotype AA, Aa and aa, respectively. And $n = n_{AA} + n_{Aa} + n_{aa}$.&lt;/p&gt;

&lt;p&gt;So, the count of A and a alleles are:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;n_{A} = 2 \times n_{AA} + n_{Aa}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;n_{a} = 2 \times n_{aa} + n_{Aa}&lt;/script&gt;

&lt;p&gt;The frequencies of A and a alleles are:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{A} = \frac{n_{A}}{2n} = \frac{2 \times n_{AA} + n_{Aa}}{2n} = p_{AA} + \frac{1}{2}p_{Aa}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{a} = \frac{n_{a}}{2n} = \frac{2 \times n_{aa} + n_{Aa}}{2n} = p_{aa} + \frac{1}{2}p_{Aa}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{A} = 1 - p_{a}&lt;/script&gt;

&lt;h4 id=&quot;from-allele-to-genotype-frequencies---hwe&quot;&gt;From Allele to Genotype frequencies - HWE&lt;/h4&gt;

&lt;p&gt;We cannot directly get genotype frequencies from allele frequencies. But under Hardy-Weiberge Equilibrium, we can do it by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{AA} = p_{A}^{2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{Aa} = 2p_{A}p_{a}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{aa} = p_{a}^{2}&lt;/script&gt;

&lt;p&gt;The assumptions for HWE includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;random mating&lt;/li&gt;
  &lt;li&gt;infinite population size (no genetic drift)&lt;/li&gt;
  &lt;li&gt;no mutation&lt;/li&gt;
  &lt;li&gt;no selection&lt;/li&gt;
  &lt;li&gt;no migration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition, we can see genotype frequencies is a binomial distribution. If SNP genotpes are coded X = 0, 1 and 2 (alleles) and the allele frequency is p, then:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X \sim B(2, p)\text{ with }E(X) = 2p\text{ and }Var(X)=2p(1-p)&lt;/script&gt;

&lt;p&gt;We can plot the distribution of three different genotypes. In real genetics, we usually use the minor allele, so p is less than 0.5.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-{r}&quot;&gt;p = seq(0,1,0.01)
plot(p, (1-p)^2, ylab = &quot;genotype frequency&quot;, main=&quot;Under HWE&quot;,type=&quot;l&quot;, col=&quot;blue&quot;)
lines(p, 2*p*(1-p), col=&quot;green&quot;)
lines(p, p^2, col=&quot;grey&quot;)
legend(0.5,0.95,&quot;genotype = 0&quot;,lty = 1, col =&quot;blue&quot;, bty=&quot;n&quot;)
legend(0.5,0.85,&quot;genotype = 1&quot;,lty = 1, col =&quot;green&quot;, bty = &quot;n&quot;)
legend(0.5,0.75,&quot;genotype = 2&quot;,lty = 1, col =&quot;grey&quot;, bty = &quot;n&quot;)
abline(v = 0.5, lty=2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/HWE_allele_genotype.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;test-for-hwe&quot;&gt;Test for HWE&lt;/h4&gt;

&lt;p&gt;In the GWAS QC step, we usually remove SNPs with extensive deviation from HWE because this can be indicative of a genotyping or genotype-calling error.&lt;/p&gt;

&lt;p&gt;The two common ways to test HWE are Chi-square test and exact test.&lt;/p&gt;

&lt;p&gt;For Chi-square test:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\chi^{2} = \frac{(n_{AA}-e{AA})^2}{e_{AA}} + \frac{(n_{Aa}-e{Aa})^2}{e_{Aa}} + \frac{(n_{aa}-e{aa})^2}{e_{aa}}&lt;/script&gt;

&lt;p&gt;where $e_{AA} = np_{A}^2$, $e_{Aa} = 2np_{A}p_{a}$, $e_{aa} = np_{a}^2$ and df = 1 (#genotype - #allele).&lt;/p&gt;

&lt;p&gt;For exact test:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(N_{Aa}|N_{A}) = \frac{n_{A}!n_{a}!n!2^{n_{Aa}}}{\frac{1}{2}(n_{A}-n_{Aa})!n_{Aa}!\frac{1}{2}(n_{a}-n_{Aa})!(2n)!}&lt;/script&gt;

&lt;p&gt;For example, a sample with 2504 individuals, the observed genotypes are 2467/36/1 for AA, Aa and aa. We can do the chi-square test in R.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;### Observed genotype counts
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_AA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2467&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_Aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_AA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_Aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;O_geno&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_AA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_Aa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_aa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;O_geno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 2467 36 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;### Observed allele count and frequency
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_A&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_AA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_Aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_Aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_A&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_a&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 0.9924121 0.007587859
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;### Expected genotype count, under HWE
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_AA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_Aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_A&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_a&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_aa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_geno&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_AA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_Aa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_aa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_geno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 2466.144 37.71166 0.1441693
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;### Chi-square with df=1 (#genotypes - #alleles)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chisq&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;O_geno&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_geno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_geno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pvalue&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pchisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;chisq:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;pvalue: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pvalue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## chisq: 5.15844350552391 ; pvalue:  0.02313362043297
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can also use the R package “HardyWeinberg” to do the chi-square test.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;### We can also use the R package &quot;HardyWeinberg&quot;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HardyWeinberg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HWChisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;O_geno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Chi-square test for Hardy-Weinberg equilibrium (autosomal)
## Chi2 =  5.158444 DF =  1 p-value =  0.02313362 D =  -0.8558307 f =  0.04538812
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It’s hard to do the exact test directly in R because of the factorial calucation. So we also use the R package “HardyWeinberg”. A more common way is to use &lt;a href=&quot;https://www.cog-genomics.org/plink/1.9/filter#hwe&quot;&gt;PLINK&lt;/a&gt; “–hwe” option.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;HWExact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;O_geno&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Haldane Exact test for Hardy-Weinberg equilibrium (autosomal)
## using SELOME p-value
## sample counts: n =  2467 n =  36 n =  1 
## H0: HWE (D==0), H1: D &amp;lt;&amp;gt; 0 
## D =  -0.8558307 p-value =  0.1318891
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We can see that the p-values from chi-square and exact test are quite different. In 2005, &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0002929707607356&quot;&gt;Wigginton et al&lt;/a&gt; has shown that the chi-square inflated type I error rates. So exact test is a better method.&lt;/p&gt;

&lt;h3 id=&quot;linkage-disequilibrium&quot;&gt;Linkage disequilibrium&lt;/h3&gt;

&lt;h4 id=&quot;disequilibrium-coefficient-d&quot;&gt;Disequilibrium coefficient (D)&lt;/h4&gt;

&lt;p&gt;For a pair of biallelic loci, there are four &lt;a href=&quot;https://en.wikipedia.org/wiki/Haplotype&quot;&gt;haplotypes&lt;/a&gt;. If there is no association between these two SNPs (linkage equilibrium), the haplotype frequencies should be:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$p_{AB} = p_{A} \times p_{B}$&lt;/li&gt;
  &lt;li&gt;$p_{aB} = p_{a} \times p_{B}$&lt;/li&gt;
  &lt;li&gt;$p_{Ab} = p_{A} \times p_{b}$&lt;/li&gt;
  &lt;li&gt;$p_{ab} = p_{a} \times p_{b}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, if the two SNPs have nonrandom association, the LD can be defined by disequilibrium coefficient:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$D_{AB} = p_{AB} - p_{A} \times p_{B}$&lt;/li&gt;
  &lt;li&gt;$P_{AB} = p_{A} \times p_{B} + D_{AB}$&lt;/li&gt;
  &lt;li&gt;$p_{aB} = p_{a} \times p_{B} - D_{AB}$&lt;/li&gt;
  &lt;li&gt;$p_{Ab} = p_{A} \times p_{b} - D_{AB}$&lt;/li&gt;
  &lt;li&gt;$p_{ab} = p_{a} \times p_{b} + D_{AB}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;other-ld-measures&quot;&gt;Other LD measures&lt;/h4&gt;

&lt;p&gt;More wildely used measures for LD are D’ and $r^{2}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D'_{AB} = \frac{D_{AB}}{D_{min}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
D_{min} = max(-p_{A}p_{B}, -p_{a}p_{b}), if D_{AB} &lt; 0 %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{min} = min(p_{A}p_{b}, p_{a}p_{B}), if D_{AB} &gt; 0&lt;/script&gt;

&lt;p&gt;D′ = 1 indicates that at least one of the four possible haplotypes is absent, regardless of the allele frequencies.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r^{2} = \frac{D^{2}}{p_{A}p_{a}p_{B}p_{b}}&lt;/script&gt;

&lt;p&gt;$r^{2}$ is a correlation coefficient of 1/0 (all or none) indicator variables indicating the presence of A and B.&lt;/p&gt;

&lt;h4 id=&quot;influence-factor&quot;&gt;Influence Factor&lt;/h4&gt;

&lt;p&gt;Linkage disequilibrium is influenced by many factors, including,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;selection&lt;/li&gt;
  &lt;li&gt;the rate of recombination&lt;/li&gt;
  &lt;li&gt;the rate of mutation&lt;/li&gt;
  &lt;li&gt;genetic drift&lt;/li&gt;
  &lt;li&gt;the system of mating&lt;/li&gt;
  &lt;li&gt;population structure&lt;/li&gt;
  &lt;li&gt;genetic linkage.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;an-example-in-r&quot;&gt;An example in R&lt;/h4&gt;

&lt;p&gt;Haplotype table&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;haplotype&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;ab&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Ab&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;aB&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;AB&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;frequency&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;32/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4975/5008&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2*2 allele frequency table&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;allele&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;a&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;A&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Total&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;b&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;32/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;32/5008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;B&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4975/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4976/5008&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;5007/5008&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#haplotype frequency
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pab&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAb&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5008&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5008&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4975&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5008&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 0 0.006389776 0.0001996805 0.9934105
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#allele frequency
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pab&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pA&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAb&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pb&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pab&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAb&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 0.0001996805 0.9998003 0.006389776 0.9936102
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#D
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pAB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pB&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## -1.275914e-06
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#Dmin
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dmin&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## -1.275914e-06
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#D'
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ddot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dmin&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ddot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#r-square
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rsq&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rsq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## 1.284376e-06
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://bioinformatics.org.au/ws09/presentations/Day3_PVisscher.pdf&quot;&gt;ppt from Peter Visscher&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.springer.com/cn/book/9781441973375&quot;&gt;Laird et al, The Fundamentals of Modern Statistical Genetics, 2011&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cran.r-project.org/web/packages/HardyWeinberg/vignettes/HardyWeinberg.pdf&quot;&gt;R package HardyWeinberg&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 07 Jun 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/06/07/HWE_LD.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/06/07/HWE_LD.html</guid>
        
        <category>genetics</category>
        
        
      </item>
    
      <item>
        <title>Simple Statistic in R</title>
        <description>&lt;p&gt;After reading all the materials of &lt;a href=&quot;http://zjuwhw.github.io/2017/05/09/Stats_MOOC.html&quot;&gt;one Statistic Mooc&lt;/a&gt;, I would like to use R to practice these statistic equations.&lt;/p&gt;

&lt;h3 id=&quot;descriptive-statistics&quot;&gt;Descriptive Statistics&lt;/h3&gt;

&lt;h4 id=&quot;sample-mean&quot;&gt;sample mean&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{x} = \frac{1}{n}\displaystyle\sum_{i=1}^{n}x_{i}&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## [1] 5.5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;sample-variance-standard-deviation&quot;&gt;sample variance, standard deviation&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(x) = \frac{1}{n-1}\displaystyle\sum_{i=1}^{n}(x_{i} - \bar{x})^{2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(x) = \frac{1}{n-1}(\displaystyle\sum_{i=1}^{n}x_{i}^{2} - n\bar{x}^2)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SD(x) = \sqrt{Var(x)}&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## [1] 9.166667
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## [1] 3.02765
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;standard-units&quot;&gt;standard units&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z = \frac{x - \mu}{\sigma}&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;##             [,1]
##  [1,] -1.4863011
##  [2,] -1.1560120
##  [3,] -0.8257228
##  [4,] -0.4954337
##  [5,] -0.1651446
##  [6,]  0.1651446
##  [7,]  0.4954337
##  [8,]  0.8257228
##  [9,]  1.1560120
## [10,]  1.4863011
## attr(,&quot;scaled:center&quot;)
## [1] 5.5
## attr(,&quot;scaled:scale&quot;)
## [1] 3.02765
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;sample-covariance&quot;&gt;sample covariance&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(x,y) = \frac{1}{n-1}\displaystyle\sum_{i=1}^{n}(x_{i} - \bar{x})(y_{i}-\bar{y})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(x,y) = \frac{1}{n-1}(\displaystyle\sum_{i=1}^{n}x_{i}y_{i}-n\bar{x}\bar{y})&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## [1] 16.11111
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;sample-correlation&quot;&gt;sample correlation:&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r = \frac{Cov(x, y)}{\sqrt{Var(x)Var(y)}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r = \frac{Cov(x, y)}{\sqrt{SD(x)SD(y)}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r = \frac{1}{n-1}\displaystyle\sum z_{x}z_{y}, \text{where }z_{x} = \frac{x - \bar{x}}{SD(x)}\text{and }z_{y} = \frac{y - \bar{y}}{SD(y)}&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## [1] 0.9715366
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;mean-rules&quot;&gt;mean rules&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;mean(x+c) = mean(x) + c&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;meam(cx) = mean(x) \times c&lt;/script&gt;

&lt;h4 id=&quot;variance-rules&quot;&gt;variance rules&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(x) = E[x − E(x)]^{2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(cx) = c^{2}Var(x)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(x + y) = Var(x) + Var(y) + 2Cov(x, y)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(x - y) = Var(x) + Var(y) - 2Cov(x, y)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(x + c) = Var(x)&lt;/script&gt;

&lt;h4 id=&quot;covariance-rules&quot;&gt;covariance rules&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(x, y) = E[(x − E(x)(y − E(y)]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(cx, y) = cCov(x, y)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(x, y + z) = Cov(x, y) + Cov(x, z)&lt;/script&gt;

&lt;h4 id=&quot;correlation-rules&quot;&gt;Correlation rules&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cor(cx, y) = Cor(x, y)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cor(x + c, y) = Cor(x, y)&lt;/script&gt;

&lt;h3 id=&quot;regression&quot;&gt;Regression&lt;/h3&gt;

&lt;h4 id=&quot;simple-linear-regression-model&quot;&gt;simple linear regression model&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_{i} = \beta_{0} + \beta_{1}x_{i} + \varepsilon_{i}&lt;/script&gt;

&lt;h4 id=&quot;least-squares-estimates&quot;&gt;Least squares estimates&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y_{i}} = \hat{\beta_{0}} + \hat{\beta_{1}}x_{i}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\beta_{0}} = \bar{y} - \beta_{1}\bar{x}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\beta_{1}} = \frac{\sum(x_{i}-\bar{x})(y_{i}-\bar{y})}{\sum(x_{i}-\bar{x})^2} = \frac{Cov(x,y)}{Var(x)} = r \times \frac{\sqrt{Var(y)}}{\sqrt{Var(x)}}&lt;/script&gt;

&lt;h3 id=&quot;distribution&quot;&gt;Distribution&lt;/h3&gt;

&lt;h4 id=&quot;all-distribution-in-r-stats-package&quot;&gt;all distribution in R stats package&lt;/h4&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distribution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;normal-distribution&quot;&gt;Normal Distribution&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
Normal(\mu, \sigma^{2}): \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^{2}}, -\infty&lt;x&lt;\infty %]]&gt;&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/stat_files/unnamed-chunk-7-1.png&quot; alt=&quot;&quot; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;h4 id=&quot;binomial-distribution&quot;&gt;Binomial Distribution&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Binomial(n,p): \binom{n}{k}p^{k}(1-p)^{n-k}, k=1,2,...,n&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbinom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;k&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;p&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/stat_files/unnamed-chunk-8-1.png&quot; alt=&quot;&quot; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;de Moivre - Laplace Theorem&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Fix any p strictly between 0 and 1. As the number of trials n increases, the probability histogram for the binomial distribution looks like the nomrla curve with mean np and SD $\sqrt{np(1-p)}$&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ncol&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbinom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paste&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n = &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;k&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;p&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/stat_files/unnamed-chunk-9-1.png&quot; alt=&quot;&quot; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;h4 id=&quot;t-distribution&quot;&gt;t distribution&lt;/h4&gt;

&lt;p&gt;With the increase of degree of freedem, t distribution is closer to the standard normal distribution.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dnorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;normal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.375&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;t, df=2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;t, df=5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.325&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;t, df=10&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/stat_files/unnamed-chunk-10-1.png&quot; alt=&quot;&quot; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;h4 id=&quot;chi-square-distribution&quot;&gt;Chi-square distribution&lt;/h4&gt;

&lt;p&gt;As the degrees of freedom increase, the chi-square curve looks more and more like a normal curve.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dchisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;l&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylab&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dchisq(x)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dchisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dchisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dchisq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;chi-sqaure, df=1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;chi-sqaure, df=2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;chi-sqaure, df=5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.175&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;chi-sqaure, df=10&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bty&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/stat_files/unnamed-chunk-11-1.png&quot; alt=&quot;&quot; /&gt;&lt;!-- --&gt;&lt;/p&gt;

&lt;h4 id=&quot;uniform-distribution&quot;&gt;Uniform distribution&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Uniform(a,b): \frac{1}{b-a}, a \leq x \leq b&lt;/script&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dunif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/stat_files/unnamed-chunk-12-1.png&quot; alt=&quot;&quot; /&gt;&lt;!-- --&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 05 Jun 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/06/05/Stats_R.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/06/05/Stats_R.html</guid>
        
        <category>statistics</category>
        
        
      </item>
    
      <item>
        <title>Use MathJax to write Equations in Jekyll blogs</title>
        <description>&lt;p&gt;My PhD field involves a lot of statistic, so I usually need to write math equations both by hands and, more convenient, on the internet. This is my solution.&lt;/p&gt;

&lt;h3 id=&quot;use-mathjax-for-jekyll&quot;&gt;Use &lt;a href=&quot;https://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; for Jekyll&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;insert the code in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_layouts/default.html&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/x-mathjax-config&quot;&amp;gt;
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
&amp;lt;/script&amp;gt;
&amp;lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The first part is used to enable inline equation.&lt;/p&gt;

&lt;h3 id=&quot;use-latex-to-write-equations&quot;&gt;Use LaTex to write equations&lt;/h3&gt;

&lt;p&gt;I found &lt;a href=&quot;https://en.wikibooks.org/wiki/LaTeX/Mathematics&quot;&gt;LaTex/Mathematics&lt;/a&gt; is wildly used to write equations on the website, such as &lt;a href=&quot;http://rmarkdown.rstudio.com/authoring_basics.html&quot;&gt;rmarkdown&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For example, use &lt;code class=&quot;highlighter-rouge&quot;&gt;$$mean = \frac{\displaystyle\sum_{i=1}^{n} x_{i}}{n}$$&lt;/code&gt; to write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;mean = \frac{\displaystyle\sum_{i=1}^{n} x_{i}}{n}&lt;/script&gt;

&lt;p&gt;Use &lt;code class=&quot;highlighter-rouge&quot;&gt;k_{n+1} = n^2 + k_n^2 - k_{n-1}&lt;/code&gt; to write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;k_{n+1} = n^2 + k_n^2 - k_{n-1}&lt;/script&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.lostinmyterminal.com/webpages/2015/01/09/math-support-in-jekyll.html&quot;&gt;http://blog.lostinmyterminal.com/webpages/2015/01/09/math-support-in-jekyll.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 04 Jun 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/06/04/MathJax.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/06/04/MathJax.html</guid>
        
        <category>statistics</category>
        
        <category>cs</category>
        
        
      </item>
    
      <item>
        <title>Statistics Mooc</title>
        <description>&lt;p&gt;This is the notebook for Berkley’s Edx course serise - &lt;a href=&quot;https://www.edx.org/course/introduction-statistics-descriptive-uc-berkeleyx-stat2-1x&quot;&gt;stat2.1&lt;/a&gt;, &lt;a href=&quot;https://www.edx.org/course/introduction-statistics-probability-uc-berkeleyx-stat2-2x&quot;&gt;stat2.2&lt;/a&gt;, &lt;a href=&quot;https://www.edx.org/course/introduction-statistics-inference-uc-berkeleyx-stat2-3x&quot;&gt;stat2.3&lt;/a&gt;.&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#stat21-descriptive-statistics&quot; id=&quot;markdown-toc-stat21-descriptive-statistics&quot;&gt;Stat2.1 Descriptive Statistics&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1-introduction&quot; id=&quot;markdown-toc-1-introduction&quot;&gt;1. Introduction&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11-why-study-descriptive-statistics&quot; id=&quot;markdown-toc-11-why-study-descriptive-statistics&quot;&gt;1.1 Why study descriptive statistics?&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12-variables-terminology&quot; id=&quot;markdown-toc-12-variables-terminology&quot;&gt;1.2 Variables terminology&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#13-bar-graphs-describing-categorical-data&quot; id=&quot;markdown-toc-13-bar-graphs-describing-categorical-data&quot;&gt;1.3 Bar graphs: describing categorical data&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-the-histogram&quot; id=&quot;markdown-toc-2-the-histogram&quot;&gt;2 The histogram&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#21-describing-one-quantitative-variable&quot; id=&quot;markdown-toc-21-describing-one-quantitative-variable&quot;&gt;2.1 Describing one quantitative variable&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#22-how-to-draw-a-histogram&quot; id=&quot;markdown-toc-22-how-to-draw-a-histogram&quot;&gt;2.2 How to draw a histogram&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#23-units-and-density&quot; id=&quot;markdown-toc-23-units-and-density&quot;&gt;2.3 Units and density&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#24-percentiles-estimaing-from-histogram&quot; id=&quot;markdown-toc-24-percentiles-estimaing-from-histogram&quot;&gt;2.4 Percentiles: estimaing from histogram&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#25-percentiles-more-carefully-from-the-data&quot; id=&quot;markdown-toc-25-percentiles-more-carefully-from-the-data&quot;&gt;2.5 Percentiles: more carefully, from the data&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-measures-of-location&quot; id=&quot;markdown-toc-3-measures-of-location&quot;&gt;3 Measures of Location&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#31-the-median-and-the-mode&quot; id=&quot;markdown-toc-31-the-median-and-the-mode&quot;&gt;3.1 The median and the mode&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#32-the-average-calculation-and-basic-properties&quot; id=&quot;markdown-toc-32-the-average-calculation-and-basic-properties&quot;&gt;3.2 The average: calculation and basic properties&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#33-comparing-and-combining-averages&quot; id=&quot;markdown-toc-33-comparing-and-combining-averages&quot;&gt;3.3 Comparing and combining averages&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#34-the-average-and-the-histogram-the-average-and-the-median&quot; id=&quot;markdown-toc-34-the-average-and-the-histogram-the-average-and-the-median&quot;&gt;3.4 The average and the histogram; the average and the median&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#35-markovs-inequality&quot; id=&quot;markdown-toc-35-markovs-inequality&quot;&gt;3.5 Markov’s inequality&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4-measures-of-spread&quot; id=&quot;markdown-toc-4-measures-of-spread&quot;&gt;4 Measures of spread&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#41-range-and-interquartile-range&quot; id=&quot;markdown-toc-41-range-and-interquartile-range&quot;&gt;4.1 Range and interquartile range&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#42-deviations-from-average-the-standard-deviation-sd&quot; id=&quot;markdown-toc-42-deviations-from-average-the-standard-deviation-sd&quot;&gt;4.2 Deviations from average; the standard deviation (SD)&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#43-properties-of-the-sd-chebychevs-inequality&quot; id=&quot;markdown-toc-43-properties-of-the-sd-chebychevs-inequality&quot;&gt;4.3 Properties of the SD; Chebychev’s inequality&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#44-changing-units-of-measurement-standard-units&quot; id=&quot;markdown-toc-44-changing-units-of-measurement-standard-units&quot;&gt;4.4 Changing units of measurement; standard units&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5-the-normal-curve&quot; id=&quot;markdown-toc-5-the-normal-curve&quot;&gt;5 The normal curve&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-bell-shaped-curves-the-standard-normal-curve&quot; id=&quot;markdown-toc-51-bell-shaped-curves-the-standard-normal-curve&quot;&gt;5.1 Bell shaped curves; the standard normal curve&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-normal-curves-relation-to-the-standard-normal&quot; id=&quot;markdown-toc-52-normal-curves-relation-to-the-standard-normal&quot;&gt;5.2 Normal curves: relation to the standard normal&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-approximating-data-histograms-percentiles-revisited&quot; id=&quot;markdown-toc-53-approximating-data-histograms-percentiles-revisited&quot;&gt;5.3 Approximating data histograms; percentiles revisited&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#54-not-all-histograms-are-bell-shaped-chebychev-revisited&quot; id=&quot;markdown-toc-54-not-all-histograms-are-bell-shaped-chebychev-revisited&quot;&gt;5.4 Not all histograms are bell shaped; Chebychev revisited&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6-relation-between-two-variables&quot; id=&quot;markdown-toc-6-relation-between-two-variables&quot;&gt;6 Relation between two variables&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#61-scatter-diagrams&quot; id=&quot;markdown-toc-61-scatter-diagrams&quot;&gt;6.1 Scatter diagrams&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#62-the-correlation-coefficient-calculation-and-properties&quot; id=&quot;markdown-toc-62-the-correlation-coefficient-calculation-and-properties&quot;&gt;6.2 The correlation coefficient: calculation and properties&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#63-using-r-with-cation&quot; id=&quot;markdown-toc-63-using-r-with-cation&quot;&gt;6.3 Using r: with cation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#7-regression&quot; id=&quot;markdown-toc-7-regression&quot;&gt;7 Regression&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#71-estimation-bivariate-normal-football-shaped-scatter-diagrams&quot; id=&quot;markdown-toc-71-estimation-bivariate-normal-football-shaped-scatter-diagrams&quot;&gt;7.1 Estimation; bivariate normal (“football shaped”) scatter diagrams&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#72-regression-line-intuition-the-equation-in-standard-units-regression-estimates&quot; id=&quot;markdown-toc-72-regression-line-intuition-the-equation-in-standard-units-regression-estimates&quot;&gt;7.2 Regression line: intuition; the equation in standard units; regression estimates&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#73-regression-effect-galton-and-the-regression-fallacy&quot; id=&quot;markdown-toc-73-regression-effect-galton-and-the-regression-fallacy&quot;&gt;7.3 Regression effect, Galton, and the regression fallacy&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#74-equation-of-the-regression-line&quot; id=&quot;markdown-toc-74-equation-of-the-regression-line&quot;&gt;7.4 Equation of the regression line&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#8-error-in-the-regression-estimate&quot; id=&quot;markdown-toc-8-error-in-the-regression-estimate&quot;&gt;8 Error in the regression estimate&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#81-least-squares-why-the-regression-line-and-no-other&quot; id=&quot;markdown-toc-81-least-squares-why-the-regression-line-and-no-other&quot;&gt;8.1 Least squares: why the regression line and no other&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#82-the-rms-error-of-regression-calculations-assuming-bivariate-normal-scatter&quot; id=&quot;markdown-toc-82-the-rms-error-of-regression-calculations-assuming-bivariate-normal-scatter&quot;&gt;8.2 The r.m.s error of regression; calculations assuming bivariate normal scatter&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#83-how-regression-is-commonly-used-estimating-an-unknown-true-line&quot; id=&quot;markdown-toc-83-how-regression-is-commonly-used-estimating-an-unknown-true-line&quot;&gt;8.3 How regression is commonly used; estimating an “unknown true line”&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#stat22-probability&quot; id=&quot;markdown-toc-stat22-probability&quot;&gt;Stat2.2 Probability&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1-the-two-fundamental-rules&quot; id=&quot;markdown-toc-1-the-two-fundamental-rules&quot;&gt;1 the two fundamental rules&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11-what-is-probability&quot; id=&quot;markdown-toc-11-what-is-probability&quot;&gt;1.1 What is probability?&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12-addition-rule&quot; id=&quot;markdown-toc-12-addition-rule&quot;&gt;1.2 Addition rule&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#13-multiplication-rule&quot; id=&quot;markdown-toc-13-multiplication-rule&quot;&gt;1.3 Multiplication rule&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#14-problem-solving-techniques&quot; id=&quot;markdown-toc-14-problem-solving-techniques&quot;&gt;1.4 Problem-solving techniques&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#15-conditional-or-unconditional&quot; id=&quot;markdown-toc-15-conditional-or-unconditional&quot;&gt;1.5 Conditional or unconditional?&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#16-bayes-rule&quot; id=&quot;markdown-toc-16-bayes-rule&quot;&gt;1.6 Bayes’ Rule&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-random-sampling-with-and-without-replacement&quot; id=&quot;markdown-toc-2-random-sampling-with-and-without-replacement&quot;&gt;2 Random sampling with and without replacement&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#21-independence&quot; id=&quot;markdown-toc-21-independence&quot;&gt;2.1 Independence&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#22-sampling-with-replacement-the-binomial-formula二项分布&quot; id=&quot;markdown-toc-22-sampling-with-replacement-the-binomial-formula二项分布&quot;&gt;2.2 Sampling with replacement: the binomial formula（二项分布）&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#23-sampling-without-replacement-the-hypergeometric超几何-formula&quot; id=&quot;markdown-toc-23-sampling-without-replacement-the-hypergeometric超几何-formula&quot;&gt;2.3 Sampling without replacement: the hypergeometric（超几何） formula&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#24-examples&quot; id=&quot;markdown-toc-24-examples&quot;&gt;2.4 Examples&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-the-law-of-averages-and-expected-values&quot; id=&quot;markdown-toc-3-the-law-of-averages-and-expected-values&quot;&gt;3 the law of averages and expected values&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#31-not-the-law-of-averages&quot; id=&quot;markdown-toc-31-not-the-law-of-averages&quot;&gt;3.1 Not the law of averages&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#32-the-law-of-averages&quot; id=&quot;markdown-toc-32-the-law-of-averages&quot;&gt;3.2 The law of averages&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#33-the-expected-value-of-a-random-sum&quot; id=&quot;markdown-toc-33-the-expected-value-of-a-random-sum&quot;&gt;3.3 The expected value of a random sum&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#34-the-expected-value-of-a-random-average&quot; id=&quot;markdown-toc-34-the-expected-value-of-a-random-average&quot;&gt;3.4 The expected value of a random average&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4-the-central-limit-theorem&quot; id=&quot;markdown-toc-4-the-central-limit-theorem&quot;&gt;4 the central limit theorem&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#41-the-standard-error-of-a-random-sum&quot; id=&quot;markdown-toc-41-the-standard-error-of-a-random-sum&quot;&gt;4.1 The standard error of a random sum&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#42-probabilities-for-the-sum-of-a-large-sample&quot; id=&quot;markdown-toc-42-probabilities-for-the-sum-of-a-large-sample&quot;&gt;4.2 Probabilities for the sum of a large sample&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#43-the-central-limit-theorem&quot; id=&quot;markdown-toc-43-the-central-limit-theorem&quot;&gt;4.3 The Central limit theorem&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#44-why-you-shouldnt-gamble&quot; id=&quot;markdown-toc-44-why-you-shouldnt-gamble&quot;&gt;4.4 Why you shouldn’t gamble&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#45-the-scope-of-the-normal-approximation&quot; id=&quot;markdown-toc-45-the-scope-of-the-normal-approximation&quot;&gt;4.5 The scope of the normal approximation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5-the-accuracy-of-simple-random-samples&quot; id=&quot;markdown-toc-5-the-accuracy-of-simple-random-samples&quot;&gt;5 the accuracy of simple random samples&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-errors-in-random-percents-and-averages&quot; id=&quot;markdown-toc-51-errors-in-random-percents-and-averages&quot;&gt;5.1 Errors in random percents and averages&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-sampling-without-replacement-the-correction-factor&quot; id=&quot;markdown-toc-52-sampling-without-replacement-the-correction-factor&quot;&gt;5.2 Sampling without replacement: the correction factor&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-accuracy&quot; id=&quot;markdown-toc-53-accuracy&quot;&gt;5.3 Accuracy&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#stat23-inference&quot; id=&quot;markdown-toc-stat23-inference&quot;&gt;Stat2.3 Inference&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1-estimating-unknown-parameters&quot; id=&quot;markdown-toc-1-estimating-unknown-parameters&quot;&gt;1 Estimating unknown parameters&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11-random-samples&quot; id=&quot;markdown-toc-11-random-samples&quot;&gt;1.1 Random samples&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12-estimating-population-averages-and-percents&quot; id=&quot;markdown-toc-12-estimating-population-averages-and-percents&quot;&gt;1.2 Estimating population averages and percents&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#13-approximate-confidence-intervals&quot; id=&quot;markdown-toc-13-approximate-confidence-intervals&quot;&gt;1.3 Approximate confidence intervals&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#14-interpreting-confidence-intervals&quot; id=&quot;markdown-toc-14-interpreting-confidence-intervals&quot;&gt;1.4 Interpreting confidence intervals&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-testing-statistical-hypotheses&quot; id=&quot;markdown-toc-2-testing-statistical-hypotheses&quot;&gt;2 Testing Statistical Hypotheses&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#21-testing-hypotheses-terminology&quot; id=&quot;markdown-toc-21-testing-hypotheses-terminology&quot;&gt;2.1 Testing hypotheses: terminology&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#22-tests-for-a-population-proportion&quot; id=&quot;markdown-toc-22-tests-for-a-population-proportion&quot;&gt;2.2 Tests for a population proportion&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#23-significance-level-and-p-value&quot; id=&quot;markdown-toc-23-significance-level-and-p-value&quot;&gt;2.3 Significance level and P-value&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#24-one-tail-or-two&quot; id=&quot;markdown-toc-24-one-tail-or-two&quot;&gt;2.4 One tail or two?&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-one-sample-and-two-sample-tests&quot; id=&quot;markdown-toc-3-one-sample-and-two-sample-tests&quot;&gt;3 One-sample and two-sample tests&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#31-z-test-for-a-population-mean&quot; id=&quot;markdown-toc-31-z-test-for-a-population-mean&quot;&gt;3.1 z-test for a population mean&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#32-t-test-for-a-population-mean&quot; id=&quot;markdown-toc-32-t-test-for-a-population-mean&quot;&gt;3.2 t-test for a population mean&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#33-testing-for-the-difference-between-means&quot; id=&quot;markdown-toc-33-testing-for-the-difference-between-means&quot;&gt;3.3 Testing for the difference between means&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#34-testing-for-the-difference-between-proportions&quot; id=&quot;markdown-toc-34-testing-for-the-difference-between-proportions&quot;&gt;3.4 Testing for the difference between proportions&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4-dependent-samples&quot; id=&quot;markdown-toc-4-dependent-samples&quot;&gt;4 Dependent Samples&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#41-paired-samples-parametric-analysis&quot; id=&quot;markdown-toc-41-paired-samples-parametric-analysis&quot;&gt;4.1 Paired samples: parametric analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#42-paired-samples-non-parametric-analysis&quot; id=&quot;markdown-toc-42-paired-samples-non-parametric-analysis&quot;&gt;4.2 Paired samples: non-parametric analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#43-randomized-experiments-method&quot; id=&quot;markdown-toc-43-randomized-experiments-method&quot;&gt;4.3 Randomized experiments: method&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#44-randomized-experiments-justification&quot; id=&quot;markdown-toc-44-randomized-experiments-justification&quot;&gt;4.4 Randomized experiments: justification&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5-window-to-a-wider-world&quot; id=&quot;markdown-toc-5-window-to-a-wider-world&quot;&gt;5 Window to a wider world&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-not-everythings-normal-chi-squared-test&quot; id=&quot;markdown-toc-51-not-everythings-normal-chi-squared-test&quot;&gt;5.1 Not everything’s normal: chi-squared test&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-how-fisher-used-the-chi-squared-test&quot; id=&quot;markdown-toc-52-how-fisher-used-the-chi-squared-test&quot;&gt;5.2 How Fisher used the chi-squared test&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-chi-squared-test-for-independence&quot; id=&quot;markdown-toc-53-chi-squared-test-for-independence&quot;&gt;5.3 Chi-squared test for independence&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#appendix&quot; id=&quot;markdown-toc-appendix&quot;&gt;Appendix&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#appendix-1--the-greek-symbols&quot; id=&quot;markdown-toc-appendix-1--the-greek-symbols&quot;&gt;Appendix 1 : The Greek Symbols&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#appendix-2--common-distribution&quot; id=&quot;markdown-toc-appendix-2--common-distribution&quot;&gt;Appendix 2 : Common Distribution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#appendix-3-how-to-choose-statistical-test&quot; id=&quot;markdown-toc-appendix-3-how-to-choose-statistical-test&quot;&gt;Appendix 3: how to choose statistical test&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;stat21-descriptive-statistics&quot;&gt;Stat2.1 Descriptive Statistics&lt;/h2&gt;

&lt;h3 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h3&gt;

&lt;h4 id=&quot;11-why-study-descriptive-statistics&quot;&gt;1.1 Why study descriptive statistics?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Statistics: The science f drawing conclusions from data&lt;/li&gt;
  &lt;li&gt;Descriptive statistics: Describing and summarizing data&lt;/li&gt;
  &lt;li&gt;Probability: Understanding and quantifying randomness&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inference: Making conclusions based on data from random samples&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Graphical descriptions –&amp;gt; Numerical summaries; single variable –&amp;gt; relation between two variables&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;12-variables-terminology&quot;&gt;1.2 Variables terminology&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;quantitative variables&lt;/li&gt;
  &lt;li&gt;contiuous and discrete&lt;/li&gt;
  &lt;li&gt;categorical and qualitative&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;13-bar-graphs-describing-categorical-data&quot;&gt;1.3 Bar graphs: describing categorical data&lt;/h4&gt;

&lt;h3 id=&quot;2-the-histogram&quot;&gt;2 The histogram&lt;/h3&gt;

&lt;h4 id=&quot;21-describing-one-quantitative-variable&quot;&gt;2.1 Describing one quantitative variable&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Stem and leaf plot&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22-how-to-draw-a-histogram&quot;&gt;2.2 How to draw a histogram&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;show the distribution&lt;/li&gt;
  &lt;li&gt;allows for the bariable to be “binned” into unequal intervals&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;23-units-and-density&quot;&gt;2.3 Units and density&lt;/h4&gt;

&lt;h4 id=&quot;24-percentiles-estimaing-from-histogram&quot;&gt;2.4 Percentiles: estimaing from histogram&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;famous percentiles
    &lt;ul&gt;
      &lt;li&gt;25th percentile = lower quartile&lt;/li&gt;
      &lt;li&gt;50th percentile = median&lt;/li&gt;
      &lt;li&gt;75th percentile = upper quartile&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;25-percentiles-more-carefully-from-the-data&quot;&gt;2.5 Percentiles: more carefully, from the data&lt;/h4&gt;

&lt;h3 id=&quot;3-measures-of-location&quot;&gt;3 Measures of Location&lt;/h3&gt;

&lt;h4 id=&quot;31-the-median-and-the-mode&quot;&gt;3.1 The median and the mode&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Mode: the value that has the highest frequency&lt;/li&gt;
  &lt;li&gt;Unimodal: one peak&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;32-the-average-calculation-and-basic-properties&quot;&gt;3.2 The average: calculation and basic properties&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;average/mean: add up all the entries in the list, then divide by the number of entries
    &lt;ul&gt;
      &lt;li&gt;Units of the average: same as the units of the list&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;33-comparing-and-combining-averages&quot;&gt;3.3 Comparing and combining averages&lt;/h4&gt;

&lt;h4 id=&quot;34-the-average-and-the-histogram-the-average-and-the-median&quot;&gt;3.4 The average and the histogram; the average and the median&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The median is unaffected by outliers&lt;/li&gt;
  &lt;li&gt;In a right-skewed distribution, the average is greater than the median&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;35-markovs-inequality&quot;&gt;3.5 Markov’s inequality&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Markov’s inequality: If a list has only non-negative entries, then the proportion of entries that are &amp;gt;= k times the average is at most $\frac{1}{k}$ (k can be any positive number)&lt;/li&gt;
  &lt;li&gt;For example:
    &lt;ul&gt;
      &lt;li&gt;Q: the average age of a group of people is 20 years. What proportion are more than 80 years old?&lt;/li&gt;
      &lt;li&gt;A: The proportion is &lt;strong&gt;at most&lt;/strong&gt; $\frac{1}{4}$ (k=4)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-measures-of-spread&quot;&gt;4 Measures of spread&lt;/h3&gt;

&lt;h4 id=&quot;41-range-and-interquartile-range&quot;&gt;4.1 Range and interquartile range&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;range = maximum - minimum&lt;/li&gt;
  &lt;li&gt;interquartile range (IQR) = upper quartile - lower quartile&lt;/li&gt;
  &lt;li&gt;“The IQR of data is 8 years” means “the middle 50% of the data are distributed over 8 years”&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;42-deviations-from-average-the-standard-deviation-sd&quot;&gt;4.2 Deviations from average; the standard deviation (SD)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;deviation from average = value - average&lt;/li&gt;
  &lt;li&gt;standard deviation (SD) = root mean square (r.m.s.) of deviations from average&lt;/li&gt;
  &lt;li&gt;variance = mean sequare of deviations from average&lt;/li&gt;
  &lt;li&gt;The average and the SD have the same units&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SD = \sqrt{\frac{1}{n}\times\displaystyle\sum_{i=1}^{n}(x_{i}-\bar{x})^2}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The vexed question of n-1&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SD = \sqrt{\frac{1}{n-1}\times\displaystyle\sum_{i=1}^{n}(x_{i}-\bar{x})^2}&lt;/script&gt;

&lt;p&gt;In some situations where you are trying to use the SD of a sample to estimate the SD of the population from which the sample was drawn, then according to some criteria, it might be better to use n-1 instead of n in the denominator.&lt;/p&gt;

&lt;h4 id=&quot;43-properties-of-the-sd-chebychevs-inequality&quot;&gt;4.3 Properties of the SD; Chebychev’s inequality&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Pafnuty Lvovich Chebychev (1821-1894)&lt;/li&gt;
  &lt;li&gt;Chebychev’s inequality: In any list, the proportion of the entries that are k or more SDs away from the average is at most &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{k^{2}}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rough statement&lt;/strong&gt;: No matter what the list, the vast majority of entries will be in the range &lt;strong&gt;average ± a few SDs&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Precise statment&lt;/strong&gt;: No matter what the list, a proportion of at least &lt;script type=&quot;math/tex&quot;&gt;1-\frac{1}{k^{2}}&lt;/script&gt;of the entries will be in the range &lt;strong&gt;average ± a few SDs&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Typical use

Age: average 20 years, SD 5 years.
What percent are more than 80 years old?

Markov's bound:
at most 25% (1/k, k = 80/20 = 4)

Chebychev's bound: 
at most 0.7% (1/k^2, k=(80-20)/5 = 12)

In conclusion, both bounds are correct.
But Chebychev's bound is much sharper.
Because it uses the SD, not just the average.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;44-changing-units-of-measurement-standard-units&quot;&gt;4.4 Changing units of measurement; standard units&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Mechanics of changing units
    &lt;ul&gt;
      &lt;li&gt;Multiplying by a constant, e.g. centimeters = 2.54 * inches&lt;/li&gt;
      &lt;li&gt;Mutliplying by a constant, then adding a constant, e.g. &lt;sup&gt;◦&lt;/sup&gt;F = (9/5)&lt;sup&gt;◦&lt;/sup&gt;C + 32&lt;/li&gt;
      &lt;li&gt;Can also first add a constant, then mulitple by a constant, e.g. new variable = (old variable + b) * a&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adding a constant
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;mean_{new} = mean_{old} + constant&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;SD_{new} = SD_{old}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Multiplying by a constant
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;mean_{mean} = mean_{old} \times constant&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;SD_{new} = SD_{old} * |constant|&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Linear transformations: new list = a * (old list) + b
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;mean_{new} = a \times mean_{old} + b&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;SD_{new} = |a| \times SD_{old}&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Standard units: the z-score
    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;z = \frac{x - mean}{SD}&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;x = z \times SD + mean&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;z measures “how many SDs above mean”&lt;/li&gt;
      &lt;li&gt;the mean of any list in standard units is 0&lt;/li&gt;
      &lt;li&gt;the SD of any list in standard units is 1&lt;/li&gt;
      &lt;li&gt;the vast majority (at least 8/9) of any list in standard units will be in the range -3 to 3&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-the-normal-curve&quot;&gt;5 The normal curve&lt;/h3&gt;

&lt;h4 id=&quot;51-bell-shaped-curves-the-standard-normal-curve&quot;&gt;5.1 Bell shaped curves; the standard normal curve&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;A bell shaped distribution&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/Bell_shaped.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The standard normal curve&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/standard_normal_curve.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;density at z&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
= \frac{1}{ \sqrt{2\pi} }e^{-\frac{1}{2}z^{2}}, -\infty &lt; z &lt; \infty %]]&gt;&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Useful to remember

total area = 1
balance point: z=0
points of inflection: z=-1, z=1

Central areas:
between z=-1 and z=1: about 68%
between z=-2 and z=2: about 95%

Tail areas:
to the left of -1: about 16%
to the right of 1: about 16%
to the left of -2: about 2.5%
to the right of 2: about 2.5%

Percentiles:
95th percentils: z=1.65, roughly
5th percentile: z=-1.65, roughly
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;52-normal-curves-relation-to-the-standard-normal&quot;&gt;5.2 Normal curves: relation to the standard normal&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The normal curve withe mean μ and SD σ&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;density at x&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
= \frac{1}{ \sqrt{2\pi}\sigma }e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^{2}}, -\infty &lt; x &lt; \infty %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Finding a percent under a normal curve&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;For a list with average 67 and SD 3,
what percent are between 63 and 67?

(63-67)/3 = -1.33 standard units
67 = 0 standard units

So, the question becomes:
Under standard normal curve,
what percent are between -1.33 and 0?

The applet says the area is 40.82%.
In R, the expression is &quot;pnorm(0) - pnorm(-1.33)&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;53-approximating-data-histograms-percentiles-revisited&quot;&gt;5.3 Approximating data histograms; percentiles revisited&lt;/h4&gt;

&lt;h4 id=&quot;54-not-all-histograms-are-bell-shaped-chebychev-revisited&quot;&gt;5.4 Not all histograms are bell shaped; Chebychev revisited&lt;/h4&gt;

&lt;h3 id=&quot;6-relation-between-two-variables&quot;&gt;6 Relation between two variables&lt;/h3&gt;

&lt;h4 id=&quot;61-scatter-diagrams&quot;&gt;6.1 Scatter diagrams&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;univariate data: histogram&lt;/li&gt;
  &lt;li&gt;bivariate data: scatter diagram&lt;/li&gt;
  &lt;li&gt;association: any relation between variables&lt;/li&gt;
  &lt;li&gt;positive association&lt;/li&gt;
  &lt;li&gt;negative association&lt;/li&gt;
  &lt;li&gt;linear association&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;62-the-correlation-coefficient-calculation-and-properties&quot;&gt;6.2 The correlation coefficient: calculation and properties&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;correlation coefficient (r): a number between -1 and 1; it measures linear association, that is, how tightly the points are clustered about a straight line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the data are $(x_{i},y_{i}), 1\leq i\leq n$, then&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r = \frac{1}{n}\sum_{i=1}^{n}(\frac{x_{i}-\mu_{x}}{\sigma_{x}})(\frac{y_{i}-\mu_{y}}{\sigma_{y}})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;r is a pure number with no units&lt;/li&gt;
  &lt;li&gt;-1 &amp;lt;= r &amp;lt;= 1&lt;/li&gt;
  &lt;li&gt;It doesn’t matter if you switch the variables x and y; r stays the same&lt;/li&gt;
  &lt;li&gt;Adding a constant to one of the lists, r stays the same&lt;/li&gt;
  &lt;li&gt;Multiplying one the lists by a positve constant, r stays the same&lt;/li&gt;
  &lt;li&gt;Multiplying just one (not both) of the list by a negative constant, r changes to -r&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;63-using-r-with-cation&quot;&gt;6.3 Using r: with cation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Association is not causation&lt;/li&gt;
  &lt;li&gt;r measures linear association&lt;/li&gt;
  &lt;li&gt;correlated: &lt;strong&gt;linearly&lt;/strong&gt; related&lt;/li&gt;
  &lt;li&gt;Even one outlier can have a noticeable effect on r&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7-regression&quot;&gt;7 Regression&lt;/h3&gt;

&lt;h4 id=&quot;71-estimation-bivariate-normal-football-shaped-scatter-diagrams&quot;&gt;7.1 Estimation; bivariate normal (“football shaped”) scatter diagrams&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Estimation: one variable, pick one value to estimate.
    &lt;ul&gt;
      &lt;li&gt;natural estimate: the average&lt;/li&gt;
      &lt;li&gt;math fact: The r.m.s. of the errors will be smallest if you choose estimator = average.&lt;/li&gt;
      &lt;li&gt;average: least squares estimate&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Estimation: two variables, given the value of one variable, estimate the value of the other
    &lt;ul&gt;
      &lt;li&gt;If the scater diagram is roughly football shaped, you can assume:
        &lt;ul&gt;
          &lt;li&gt;the distributions of both the variables are roughly normal&lt;/li&gt;
          &lt;li&gt;the distribution of values in each vertical and horizontal strip is roughly normal&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;72-regression-line-intuition-the-equation-in-standard-units-regression-estimates&quot;&gt;7.2 Regression line: intuition; the equation in standard units; regression estimates&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y} = r \times x, r is the correlation coefficient and x, y in standard units&lt;/script&gt;

&lt;h4 id=&quot;73-regression-effect-galton-and-the-regression-fallacy&quot;&gt;7.3 Regression effect, Galton, and the regression fallacy&lt;/h4&gt;

&lt;h4 id=&quot;74-equation-of-the-regression-line&quot;&gt;7.4 Equation of the regression line&lt;/h4&gt;

&lt;p&gt;the equation in three ways&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$\hat{y} = r \times x$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$ \frac{\hat{y} - \mu_{y}}{\sigma_{y}} = r \times \frac{x - \mu_{x}}{\sigma_{x}}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\hat{y} = slope \times x + intercept$, where $slope = r \times \frac{\sigma_{y}}{\sigma_{x}}$ and $intercept = \mu_{y} - slope \times \mu_{x}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;8-error-in-the-regression-estimate&quot;&gt;8 Error in the regression estimate&lt;/h3&gt;

&lt;h4 id=&quot;81-least-squares-why-the-regression-line-and-no-other&quot;&gt;8.1 Least squares: why the regression line and no other&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;How much error?
    &lt;ul&gt;
      &lt;li&gt;error = vertical distance between the point and the line, for every point in the scatter diagram&lt;/li&gt;
      &lt;li&gt;rough size of error = r.m.s of errors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;regreesion line: least squares line&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;82-the-rms-error-of-regression-calculations-assuming-bivariate-normal-scatter&quot;&gt;8.2 The r.m.s error of regression; calculations assuming bivariate normal scatter&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;r.m.s. error of regression = r.m.s. of residuals = &lt;script type=&quot;math/tex&quot;&gt;\sqrt{1-r^2} \times SD_{y}&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;r = 1 or -1: r.m.s. error of regression = 0, which says, scatter is a perfect straight line; regression makes no error.&lt;/li&gt;
      &lt;li&gt;r = 0: r.m.s. error of regression = SD of y, which says, no linear association; regression is the same as using the average.&lt;/li&gt;
      &lt;li&gt;All other r: Regression is not perfect, but better than using the average.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;one variable&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;two variables&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;normal curve&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;football shaped scatter diagram&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;average&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;regression line&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SD&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;r.m.s. error of regression&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Some useful analogies
    &lt;ul&gt;
      &lt;li&gt;For about 68% of the points, the regression estimate of correct to within 1 r.m.s. error.&lt;/li&gt;
      &lt;li&gt;For about 95% of the points, the regression estimate is correct to within 2 r.m.s. errors.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Residual plot
    &lt;ul&gt;
      &lt;li&gt;the average of the residuals is always 0&lt;/li&gt;
      &lt;li&gt;there is no linear association between the residuals and x&lt;/li&gt;
      &lt;li&gt;the residual plot cannot show any trend or linear relation&lt;/li&gt;
      &lt;li&gt;Good regression: residual plot looks like a formless blob around the horizontal axis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;83-how-regression-is-commonly-used-estimating-an-unknown-true-line&quot;&gt;8.3 How regression is commonly used; estimating an “unknown true line”&lt;/h4&gt;

&lt;h2 id=&quot;stat22-probability&quot;&gt;Stat2.2 Probability&lt;/h2&gt;

&lt;h3 id=&quot;1-the-two-fundamental-rules&quot;&gt;1 the two fundamental rules&lt;/h3&gt;

&lt;h4 id=&quot;11-what-is-probability&quot;&gt;1.1 What is probability?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;probability of an event = number of outcomes in the event / total number of outcomes&lt;/li&gt;
  &lt;li&gt;Frequency theory, long run proportion&lt;/li&gt;
  &lt;li&gt;Many probabilities can’t interpreted as long run frequencies, because they are based on experiments that can’t be repeated under identical conditions&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;12-addition-rule&quot;&gt;1.2 Addition rule&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Probabilities are numbers between 0 and 1&lt;/li&gt;
  &lt;li&gt;Notation
    &lt;ul&gt;
      &lt;li&gt;P(A) is read as “the probability that the event A occurs”&lt;/li&gt;
      &lt;li&gt;P(A): “probability of A”&lt;/li&gt;
      &lt;li&gt;P(coin lands heads), P(heads), P(H)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Venn diagrams&lt;/li&gt;
  &lt;li&gt;Addition rule: P(A or B) = P(A) + P(B), if A and B are mutually exclusive.&lt;/li&gt;
  &lt;li&gt;inclusion-exclusion formula: P(A or B) = P(A) + P(B) - P(A and B) for all A and B&lt;/li&gt;
  &lt;li&gt;Complement rule: P(not A) = 1 - P(A)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;13-multiplication-rule&quot;&gt;1.3 Multiplication rule&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;P(B|A)&lt;/code&gt;: &lt;strong&gt;conditional probability&lt;/strong&gt; of B, given that A has happened&lt;/li&gt;
  &lt;li&gt;Multiplication Rule: &lt;code class=&quot;highlighter-rouge&quot;&gt;P(A and B) = P(A) * P(B|A)&lt;/code&gt; for all A, B&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;14-problem-solving-techniques&quot;&gt;1.4 Problem-solving techniques&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;get started on a solution
    &lt;ul&gt;
      &lt;li&gt;be precise in your use of terminology and notation&lt;/li&gt;
      &lt;li&gt;pay attention to detail&lt;/li&gt;
      &lt;li&gt;avoid rushing to conclusions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;15-conditional-or-unconditional&quot;&gt;1.5 Conditional or unconditional?&lt;/h4&gt;

&lt;h4 id=&quot;16-bayes-rule&quot;&gt;1.6 Bayes’ Rule&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;P(A) = 0.8; P(B) = 0.2; P(bad|A) = 0.01; P(bad|B) = 0.02

P(A and bad)
 = P(A) * P(bad|A)
 = 0.8 * 0.01 
 = 0.008
P(bad)
 = P(A and bad) + P(B and bad) 
 = P(A) * P(bad|A) + P(B) * P(bad|B) 
 = 0.008 + 0.004 
 = 0.012
P(A|bad)
 = P(A and bad) / P(bad) 
 = 0.008/0.012 
 = 0.67
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Bayes’Rule: Use it to find the conditional probability of an event at an earlier stage, given the result of a later stage.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-random-sampling-with-and-without-replacement&quot;&gt;2 Random sampling with and without replacement&lt;/h3&gt;

&lt;h4 id=&quot;21-independence&quot;&gt;2.1 Independence&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Definition of conditional probability: &lt;code class=&quot;highlighter-rouge&quot;&gt;P(A and B) = P(A) * P(B|A)&lt;/code&gt;;&lt;code class=&quot;highlighter-rouge&quot;&gt; P(B|A) = P(A and B)/P(A)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;independent trials
    &lt;ul&gt;
      &lt;li&gt;tosses of a coin&lt;/li&gt;
      &lt;li&gt;rolls of a die&lt;/li&gt;
      &lt;li&gt;draws with replacement&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;dependent trials
    &lt;ul&gt;
      &lt;li&gt;cards dealt from a deck&lt;/li&gt;
      &lt;li&gt;draws without replacement&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Independent events
    &lt;ul&gt;
      &lt;li&gt;Two events A and B are independent if &lt;code class=&quot;highlighter-rouge&quot;&gt;P(B|A) = P(B|not A) = P(B)&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;P(A and B) = P(A) * P(B)&lt;/code&gt;, if A and B are independent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22-sampling-with-replacement-the-binomial-formula二项分布&quot;&gt;2.2 Sampling with replacement: the binomial formula（二项分布）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;n independent S/F trials (Bernoulli trials)&lt;/li&gt;
  &lt;li&gt;p: chance of success on each signle trial&lt;/li&gt;
  &lt;li&gt;Bionomial formula&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For k = 0,1,2,…,n, the chane of exactly k successes is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\binom{n}{k}p^{k}(1-p)^{n-k} = \frac{n!}{k!(n-k)!}p^{k}(1-p)^(n-k)&lt;/script&gt;

&lt;h4 id=&quot;23-sampling-without-replacement-the-hypergeometric超几何-formula&quot;&gt;2.3 Sampling without replacement: the hypergeometric（超几何） formula&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;N: population size&lt;/li&gt;
  &lt;li&gt;G: number of good elements in population&lt;/li&gt;
  &lt;li&gt;n: simple random sample size&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The chance that the sample contains g good elements is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\binom{G}{g}\binom{N-G}{n-g}}{\binom{N}{n}}&lt;/script&gt;

&lt;h4 id=&quot;24-examples&quot;&gt;2.4 Examples&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;geometric distribution: waiting time till the first sucess; (1-p)&lt;sup&gt;k-1&lt;/sup&gt;*(p) for k = 1, 2, 3…&lt;/li&gt;
  &lt;li&gt;negative binomial probabilites&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-the-law-of-averages-and-expected-values&quot;&gt;3 the law of averages and expected values&lt;/h3&gt;

&lt;h4 id=&quot;31-not-the-law-of-averages&quot;&gt;3.1 Not the law of averages&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;move from exact &lt;strong&gt;calculations&lt;/strong&gt; to &lt;strong&gt;approximations&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Law of averages:
    &lt;ul&gt;
      &lt;li&gt;As you keep tossing, in the long run you get &lt;strong&gt;about half&lt;/strong&gt; heads.&lt;/li&gt;
      &lt;li&gt;It is about the &lt;strong&gt;proportion&lt;/strong&gt; of heads being close to 1/2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;32-the-law-of-averages&quot;&gt;3.2 The law of averages&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;More formal statment
    &lt;ul&gt;
      &lt;li&gt;As you keep tossing, in the long run, the chance that the &lt;strong&gt;proportion of heads&lt;/strong&gt; is in the range &lt;strong&gt;0.5 ± a fixed amount&lt;/strong&gt; goes to 1&lt;/li&gt;
      &lt;li&gt;You can choose the &lt;strong&gt;fixed amount&lt;/strong&gt; to be as small as you want, as long as you keep it fixed as the number of tosses goes up.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Law of large numbers
    &lt;ul&gt;
      &lt;li&gt;independent, repeated, success-failur trials&lt;/li&gt;
      &lt;li&gt;probability of success on a single trial: p&lt;/li&gt;
      &lt;li&gt;As the number of trials increases, the chance that the proportion of successes is in range &lt;strong&gt;p ± a fixed amount&lt;/strong&gt; goes to 1.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;33-the-expected-value-of-a-random-sum&quot;&gt;3.3 The expected value of a random sum&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Notation:
    &lt;ul&gt;
      &lt;li&gt;random variables: X, Y&lt;/li&gt;
      &lt;li&gt;the sum of the first n X’s: S&lt;sub&gt;n&lt;/sub&gt; = X&lt;sub&gt;1&lt;/sub&gt; + X&lt;sub&gt;2&lt;/sub&gt;+ … X&lt;sub&gt;n&lt;/sub&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X: the number of spots on one rool of a die
Probability distribution table for X:
 - spot 1: 1/6
 - spot 2: 1/6
 - spot 3: 1/6
 - spot 4: 1/6
 - spot 5: 1/6
 - spot 6: 1/6

Long run average value of X:
1*1/6 + 2*1/6 + 3*1/6 + 4*1/6 + 5*1/6 + 6*1/6 = 3.5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Expected value of X = expectation of X = E(X)&lt;/li&gt;
  &lt;li&gt;Let X&lt;sub&gt;1&lt;/sub&gt;, X&lt;sub&gt;2&lt;/sub&gt;,…, X&lt;sub&gt;n&lt;/sub&gt;, be independent and identically distributed (i.i.d.) random variables, and let S&lt;sub&gt;n&lt;/sub&gt; = X&lt;sub&gt;1&lt;/sub&gt; + X&lt;sub&gt;2&lt;/sub&gt;+ … X&lt;sub&gt;n&lt;/sub&gt;. Then, E(S&lt;sub&gt;n&lt;/sub&gt;) = n*E(X&lt;sub&gt;1&lt;/sub&gt;)&lt;/li&gt;
  &lt;li&gt;Exected value of the binomial, E(X) = np&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;34-the-expected-value-of-a-random-average&quot;&gt;3.4 The expected value of a random average&lt;/h4&gt;

&lt;h3 id=&quot;4-the-central-limit-theorem&quot;&gt;4 the central limit theorem&lt;/h3&gt;

&lt;h4 id=&quot;41-the-standard-error-of-a-random-sum&quot;&gt;4.1 The standard error of a random sum&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Standard error
    &lt;ul&gt;
      &lt;li&gt;The standard error of &lt;strong&gt;a random variable X&lt;/strong&gt; is defined by $SE(X) = \sqrt{E((X-E(X))^{2})}$&lt;/li&gt;
      &lt;li&gt;SE(X) measures the rough sie of the chance error in X: roughly how far off X is from E(X)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Standard deviation
    &lt;ul&gt;
      &lt;li&gt;The standard deviation of &lt;strong&gt;a list of numbers&lt;/strong&gt;: SD = r.m.s. of the deviations from average&lt;/li&gt;
      &lt;li&gt;The SD measures the rough size of the deviations: roughly how far off the numbers are from the average&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X: one draw at random from 1,2,2,3

X: 
P(X = 1) = 1/4
P(X = 2) = 1/2
P(X = 3) = 1/4
E(X) = 2 = average of the box

X-E(X)
P(-1) = 1/4
P(0) = 1/2
P(1) = 1/4
E(X-E(X)) = 0

(X-E(X))^2
P(0) = 1/2
P(1) = 1/2
E((X-E(X))^2) = 0.5

standard error of X = SE(X) = sqrt(E((X-E(X))^2)) = 0.71
= SD of the box (note: for one draw, n = 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;n draws at random with replacment from a box of numbered tickets&lt;/li&gt;
  &lt;li&gt;average of the box = $\mu$     SD of the box = $\sigma$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Expected value of the sum of draws,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E = n\mu&lt;/script&gt;

&lt;p&gt;SE of the sum of draws&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SE = \sqrt{n}\mu&lt;/script&gt;

&lt;h4 id=&quot;42-probabilities-for-the-sum-of-a-large-sample&quot;&gt;4.2 Probabilities for the sum of a large sample&lt;/h4&gt;

&lt;p&gt;X has the binomial distribution with parameters n and p:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;X is the number of successes in n repeated, independent success-failure trials with probability p of success on a single trial&lt;/li&gt;
  &lt;li&gt;X is the sum of n draws with replacement from a 0-1 box that has a proportion p of 1’s&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Probability distribution of X:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\text{X = k}) = \binom{n}{k}p^{k}(1-p)^{n-k}, k=0,1,2,...n&lt;/script&gt;

&lt;p&gt;Expected value of X:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(X) = np&lt;/script&gt;

&lt;p&gt;Standard error of X:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SE(X) = \sqrt{np(1-p)}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;de Moivre - Laplace Theorem
    &lt;ul&gt;
      &lt;li&gt;Fix any p strictly between 0 and 1. As the number of trials n increases, the probability histogram for the binomial distribution looks like the nomrla curve with mean np and SD $\sqrt{np(1-p)}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;43-the-central-limit-theorem&quot;&gt;4.3 The Central limit theorem&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Central limit theorem
    &lt;ul&gt;
      &lt;li&gt;Rough statment, in English: The probability histogram for the sum of a large number of draws at random with replacement from a box of numbered tickets is approximately normal, regardless of the contents of the box&lt;/li&gt;
      &lt;li&gt;Rough statment, in math language: Let X1, X2, …, Xn be independent and identically distributed, each with expected value μ and standard error σ. Let Sn = X1 + X2 + … + Xn. Then for large n, the probability distribution of Sn is approximately normal with mean nμ and SD sqrt(n)σ, no matter what the distribution of each Xi.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;44-why-you-shouldnt-gamble&quot;&gt;4.4 Why you shouldn’t gamble&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Better to use the exact binomial&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;45-the-scope-of-the-normal-approximation&quot;&gt;4.5 The scope of the normal approximation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;It takes lots of draws for the probability histogram for the sum to start looking normal if the contents of the box
    &lt;ul&gt;
      &lt;li&gt;are far from symmetric, for exaple skewed&lt;/li&gt;
      &lt;li&gt;have a histogram that has gaps&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practical advice: Calculate expected value ± 3SE and check whether you are hitting impossible values for the variable
    &lt;ul&gt;
      &lt;li&gt;if you are, the don’t use the normal approximation&lt;/li&gt;
      &lt;li&gt;If you are not, then go ahead, but be aware that it still might not be great …&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-the-accuracy-of-simple-random-samples&quot;&gt;5 the accuracy of simple random samples&lt;/h3&gt;

&lt;h4 id=&quot;51-errors-in-random-percents-and-averages&quot;&gt;5.1 Errors in random percents and averages&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Accuracy of sample average
    &lt;ul&gt;
      &lt;li&gt;population: list of numbers&lt;/li&gt;
      &lt;li&gt;n draws at random with replacement from a population that has mean μ and SD σ&lt;/li&gt;
      &lt;li&gt;S = sample sum
        &lt;ul&gt;
          &lt;li&gt;E(S) = nμ&lt;/li&gt;
          &lt;li&gt;SE(S) = $\sqrt{n}\sigma$&lt;/li&gt;
          &lt;li&gt;CLT: If n is large, the distribution of S is roughly normal&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;M = sample mean = $\frac{S}{n}$
        &lt;ul&gt;
          &lt;li&gt;E(M) = E($\frac{S}{n}$) = $\frac{n\mu}{n} = \mu$&lt;/li&gt;
          &lt;li&gt;SE(M) = SE(S/n) = $\frac{\sqrt{n}\sigma}{n} = \frac{\sigma}{\sqrt{n}}$&lt;/li&gt;
          &lt;li&gt;CLT: If n is large, the distribution of M is roughly normal&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;52-sampling-without-replacement-the-correction-factor&quot;&gt;5.2 Sampling without replacement: the correction factor&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;populations: list of N numbers; mean μ and SD σ&lt;/li&gt;
  &lt;li&gt;simple ramdom sample of n of these numbers &lt;strong&gt;without replacement&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;S = sample sum
    &lt;ul&gt;
      &lt;li&gt;E(S) = nμ&lt;/li&gt;
      &lt;li&gt;SE(S) = $\sqrt{n}\sigma \times \sqrt{\frac{N-n}{N-1}}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;M = sample mean
    &lt;ul&gt;
      &lt;li&gt;E(M) = $\mu \times \sqrt{\frac{N-n}{N-1}}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$\sqrt{\frac{N-n}{N-1}}$, which is a correction factor (finite population correction), &amp;lt; 1&lt;/li&gt;
  &lt;li&gt;When population size N is very large and random sample size n is relatively small, $\sqrt{\frac{N-n}{N-1}}$ ≈ 1, so sampling &lt;strong&gt;without&lt;/strong&gt; replacement is almost the same as sampling &lt;strong&gt;with&lt;/strong&gt; replacement.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Central Limit Theorem (sort of )&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Consider a population of size N, with mean μ and SD σ.
Draw a simple random sample of size n.
Then, if n is large in absolute terms but small relative to N:
- the distribution of the sample sum is roughly normal with mean nμ and SE approximately sqrt(n)σ
- the distribution of the sample mean is roughly normal with mean μ and SE approximately σ/sqrt(n)
regardless of the distribution of the population
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Why didn’t we use the correction factor?
    &lt;ul&gt;
      &lt;li&gt;We don’t have the population size, but we know it’s so big that correction factor will be close to 1.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Zeros and ones&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;population of G good elements (1’s) and B bad elements (0’s)&lt;/li&gt;
  &lt;li&gt;population size N = G + B&lt;/li&gt;
  &lt;li&gt;simple random sample size n&lt;/li&gt;
  &lt;li&gt;X: number of good elements in sample: hypergeometric N, G, n&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(X) = n\frac{G}{N}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;SE(X) = \sqrt{n\times\frac{G}{N}\times\frac{B}{N}}\times\sqrt{\frac{N-n}{N-1}} \approx \sqrt{n\times\frac{G}{N}\times\frac{B}{N}}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Provided n is small relative to N, it’s same as binomial&lt;/li&gt;
  &lt;li&gt;If n is large, but small relative to N, the distribution of X is roughly normal.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;53-accuracy&quot;&gt;5.3 Accuracy&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Square Root law
    &lt;ul&gt;
      &lt;li&gt;If you multiply the sample size by a factor, the accuracy goes up by the square root of the factor&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;stat23-inference&quot;&gt;Stat2.3 Inference&lt;/h2&gt;

&lt;h3 id=&quot;1-estimating-unknown-parameters&quot;&gt;1 Estimating unknown parameters&lt;/h3&gt;

&lt;h4 id=&quot;11-random-samples&quot;&gt;1.1 Random samples&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Terminology
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Population&lt;/strong&gt;: a collection of units or individuals&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Parameter&lt;/strong&gt;: a number associated with the population&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Sample&lt;/strong&gt;: a subset of the population&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Estimate&lt;/strong&gt;: a number computed from the sample, and used as a guess for the parameter&lt;/li&gt;
      &lt;li&gt;Try to avoid or reduce &lt;strong&gt;bias&lt;/strong&gt; in the sample
        &lt;ul&gt;
          &lt;li&gt;Selection bias&lt;/li&gt;
          &lt;li&gt;Non-response bias&lt;/li&gt;
          &lt;li&gt;Bigger isn’t always better. If the method of sampling is bad, taking a large sample doesn’t help. You just get a big bad sample.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Random sample&lt;/strong&gt; or &lt;strong&gt;probability sample&lt;/strong&gt;: Before the sample is drawn, it has to be possible to calculate the probability (doesn’t have to be the same) with each member of the population will be included in the sample.&lt;/li&gt;
  &lt;li&gt;Types of samples
    &lt;ul&gt;
      &lt;li&gt;sample of convenience, not a random sample&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;simple random sample&lt;/strong&gt;: draws uniformly at random without replacement from the population; random sample&lt;/li&gt;
      &lt;li&gt;Cluster sample: random smaple&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;12-estimating-population-averages-and-percents&quot;&gt;1.2 Estimating population averages and percents&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling assumption: Simple random sample; large, but still small relative to the population, so that the correction factor is almost 1.&lt;/li&gt;
  &lt;li&gt;Bootstrap method - use sample SD as an approximation to population SD&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;13-approximate-confidence-intervals&quot;&gt;1.3 Approximate confidence intervals&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;sampling assumptions:
    &lt;ul&gt;
      &lt;li&gt;simple random sample&lt;/li&gt;
      &lt;li&gt;large enough so that the probability histogram for the sample mean or sample percent is roughly normal by &lt;strong&gt;Central Limit Theorem&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;but small enough relative to the population size that the correction factor is close to 1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;confidence intervals: sample mean ± 2 * SE of sample mean&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;14-interpreting-confidence-intervals&quot;&gt;1.4 Interpreting confidence intervals&lt;/h4&gt;

&lt;h3 id=&quot;2-testing-statistical-hypotheses&quot;&gt;2 Testing Statistical Hypotheses&lt;/h3&gt;

&lt;h4 id=&quot;21-testing-hypotheses-terminology&quot;&gt;2.1 Testing hypotheses: terminology&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Terminology and method
    &lt;ul&gt;
      &lt;li&gt;null hypothesis: H&lt;sub&gt;0&lt;/sub&gt;&lt;/li&gt;
      &lt;li&gt;alternative hypothesis: H&lt;sub&gt;1&lt;/sub&gt;&lt;/li&gt;
      &lt;li&gt;Assuming the null is true, the chance of getting data like the data in the sample or even more like the alternative: P-value&lt;/li&gt;
      &lt;li&gt;Methods: If P is small, choose the altrnative. Otherwise, stay with the null&lt;/li&gt;
      &lt;li&gt;Conventional definition:
        &lt;ul&gt;
          &lt;li&gt;“small”: P&amp;lt;5%, the result is &lt;strong&gt;statistically significant&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;“very small”: P&amp;lt;1%, the result is &lt;strong&gt;highly statistically significant&lt;/strong&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22-tests-for-a-population-proportion&quot;&gt;2.2 Tests for a population proportion&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Testing for a binomial p&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Genetic theory: each plant has a 25% chance of being red-flowering.
Experiment data: 400 plants of this species; 88 are red-flowering
Question: Is the theory good, or are ther two few red?
Answer:
n=400; H0:p=0.25; H1:p&amp;lt;0.25

exact binomial test:
P(k&amp;lt;=88)=9.08%

one-sample z test:
approximately normal with mean 100 (400*0.25) and SD 8.66(sqrt(400*0.25*0.75))
z = (88.5 - 100)/8.66 = -1.328
P-value = 9.21%
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;23-significance-level-and-p-value&quot;&gt;2.3 Significance level and P-value&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;H0: p = 0.5&lt;/li&gt;
  &lt;li&gt;H1: p = 0.8&lt;/li&gt;
  &lt;li&gt;experiments: coin will be tossed 20 times&lt;/li&gt;
  &lt;li&gt;test: if the number of heads is 14 or more, choose H1; otherwise choose H0&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;test concludes: p=0.5(Not Reject H0)&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;test concludes: p=0.8(Reject H0)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;reality is 0.5&lt;br /&gt;(H0 is true)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;correct conclusion&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;type I error&lt;br /&gt;Probability: binomial, n=20, p=0.5, P(k&amp;gt;=14)=5.8% &lt;br /&gt; &lt;strong&gt;significance level&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;reality is 0.8&lt;br /&gt;(H0 is false)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;type II error&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;correct conclusion&lt;br /&gt;Probability: binomial, n=20, p=0.8, P(k&amp;gt;=14)=91.3% &lt;br /&gt; &lt;strong&gt;power&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Two criteria for a good test
    &lt;ul&gt;
      &lt;li&gt;significance level = probability, under H0, that the test concludes H1 error probabilty, should be small&lt;/li&gt;
      &lt;li&gt;power = Probability, under H1, that the test concludes H1 probability of correct conclusion, should be large&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;24-one-tail-or-two&quot;&gt;2.4 One tail or two?&lt;/h4&gt;

&lt;h3 id=&quot;3-one-sample-and-two-sample-tests&quot;&gt;3 One-sample and two-sample tests&lt;/h3&gt;

&lt;h4 id=&quot;31-z-test-for-a-population-mean&quot;&gt;3.1 z-test for a population mean&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;H0: μ = 69.5&lt;/li&gt;
  &lt;li&gt;H1: μ &amp;lt; 69.5&lt;/li&gt;
  &lt;li&gt;SRS: n=100, mean=69, sd=2.5&lt;/li&gt;
  &lt;li&gt;If the null were true,&lt;/li&gt;
  &lt;li&gt;expectd value of sample mean = 69.5&lt;/li&gt;
  &lt;li&gt;SE of sample mean = population SD / sqrt(n) ≈ sample SD / sqrt(n) = 0.25&lt;/li&gt;
  &lt;li&gt;z = (69-69.5)/0.25 = -2, P ≈ 2.5%&lt;/li&gt;
  &lt;li&gt;Conclustion: Reject the null; μ &amp;lt; 69.5&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;32-t-test-for-a-population-mean&quot;&gt;3.2 t-test for a population mean&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;H0: μ = 30&lt;/li&gt;
  &lt;li&gt;H1: μ &amp;gt; 30&lt;/li&gt;
  &lt;li&gt;SRS: n=5, mean=31.56 (31.8, 30.9, 34.2, 32.1, 28.8)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sample is small; can’t apply Central Limit Theorem to the distribution fo the sample mean; can’t assume the probabilities for sample mean are normal.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If the null were true,&lt;/li&gt;
  &lt;li&gt;expected value of sample mean = 30&lt;/li&gt;
  &lt;li&gt;SE of sample mean = ??/sqrt(5)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How to approximate ?? based on such a small sample?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Better estimate of unknown σ is a bit bigger&lt;/li&gt;
  &lt;li&gt;SD of sample * sqrt(n/n-1)&lt;/li&gt;
  &lt;li&gt;SE of sample mean = 1.94604/sqrt(5) = 0.877&lt;/li&gt;
  &lt;li&gt;t = (31.56-30)/0.877 = 1.79&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;t distribution&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;close relative of z&lt;/li&gt;
  &lt;li&gt;there are many t curves, one for each sample size&lt;/li&gt;
  &lt;li&gt;degrees of freedom = n -1&lt;/li&gt;
  &lt;li&gt;P = 7.2% &amp;gt; 5%&lt;/li&gt;
  &lt;li&gt;Conclusion: Don’t reject null; belief that population mean = 30 isn’t bad&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One-sample t test: summary of method&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Test for a population mean (unknown SD); sample size n&lt;/li&gt;
  &lt;li&gt;One-sample t test is just like one-sample z test for population mean&lt;/li&gt;
  &lt;li&gt;Same null and alternative hypotheses, same calculation, except:
    &lt;ul&gt;
      &lt;li&gt;Assume population distribution roughly normal, unknown mean and SD&lt;/li&gt;
      &lt;li&gt;Approximate unknown SD of population by sample SD, with n-1 in the denominator&lt;/li&gt;
      &lt;li&gt;Use t curve, degrees of freedom = n-1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;33-testing-for-the-difference-between-means&quot;&gt;3.3 Testing for the difference between means&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;SE of the difference between independent random variables: SE(X-Y) = sqrt(Var(X) + Var(Y))&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SRS1(e.g. average household income in City A): n=200, mean=518, SD=100
SRS2(e.g. average household income in City B): n=250, mean=509, SD=110
H0: μ1 = μ2
H1: μ1 &amp;gt; μ2

If the null were true,
expected difference between the sample means would be 0,
with an SE of approximately:
SE = sqrt(SE1^2 + SE2^2) = sqrt((SD1/sqrt(n1))^2 + (SD2/sqrt(n2))^2) = 9.92

But observed difference between the sample means is 9,
z = (9-0)/9.92 = 0.907
the P-value is 18.2%

Conclusion: Stay with the null; the difference just looks like chance variation.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;34-testing-for-the-difference-between-proportions&quot;&gt;3.4 Testing for the difference between proportions&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SRS1: n=500, proportion=34%
SRS2: n=750, proportion=40%
H0: p1 = p2
H1: p1 &amp;lt; p2

Observed difference in sample percents: 6%

If the null is true,
expected difference in sample percents is 0,
both sample are from a population with a propotion
phat = (p1 * n1) + (p2 * n2) = 0.376
SE1 ≈ sqrt(phat*(1-phat)/n1) = 0.022
SE2 ≈ sqrt(phat*(1-phat)/n2) = 0.018
SE of the difference between the sample percents is approximately
sqrt(SE1^2 + SE2^2) = 2.8%
z = (6%-0)/2.8% = 2.14
p-value ≈ 1.6%

Conclusion: Alternative
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;4-dependent-samples&quot;&gt;4 Dependent Samples&lt;/h3&gt;

&lt;h4 id=&quot;41-paired-samples-parametric-analysis&quot;&gt;4.1 Paired samples: parametric analysis&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SRS(e.g. students): n=100
measure1(e.g. math score): mean=68, SD=12
measure2(e.g. verbal score): mean=72, SD=14
H0: md = 0 (md = measure1 - measure2)
H1: md != 0

Observed md: -4

If the null is ture,
expected md is 0,
the SE ???

Caclulate the SD of md in SRS = 11.76
OR
SD = sqrt(var(x) + var(y) - 2Cov(x,y)) = 11.76
(because x, y are not independent)

SE = 11.76/sqrt(100) = 1.176
z = (-4 - 0)/1.176 = -3.4
P is tiny

Conclusion: Reject the null
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;42-paired-samples-non-parametric-analysis&quot;&gt;4.2 Paired samples: non-parametric analysis&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SRS(e.g. students): n=100
measure1(e.g. math score): mean=68, SD=12
measure2(e.g. verbal score): mean=72, SD=14
H0: md = 0 (md = measure1 - measure2)
H1: md != 0

Calculate the number (e.g. 62) of measure1 - measure2 &amp;lt; 0
p = binomial(k&amp;gt;=62, n, 0.5) = 1.05%

Conclusion: md &amp;lt; 0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;The calculation ignores much of the information in the scores&lt;/li&gt;
  &lt;li&gt;Difference di = xi-yi is math - varbal for Student i. Test just used the number of differences that were negative.&lt;/li&gt;
  &lt;li&gt;Throws away the scores (apart from these signs), so can be quite rough&lt;/li&gt;
  &lt;li&gt;But easier to carry out than our previous method, and requires no additional assumptions when the sample is small.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;43-randomized-experiments-method&quot;&gt;4.3 Randomized experiments: method&lt;/h4&gt;

&lt;p&gt;A sample of randomized controlled experiments&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- experiment to test effectiveness of &quot;cheat sheets&quot; on probability exame
- 300 students agree to participate in a study
- Treatment group: SRS of 200 is allowed to bring cheat-sheet into the exam.
- Control group: The remaining 100 take the exam without the cheat-sheet.
- Data:
	- Treatment group: mean=75, SD=15
	- Control group: mean=80, SD=12

- Did the treatment hurt?
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Method: use the two-sample z test.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;44-randomized-experiments-justification&quot;&gt;4.4 Randomized experiments: justification&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Dubious step 1: &lt;code class=&quot;highlighter-rouge&quot;&gt;1/sqrt(200) = 1.06, 12/sqrt(100)=1.2&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;Missing the correction factor. The correction factor cannot be ignored due to the raito of sample size (100 or 200) and population size (300)&lt;/li&gt;
      &lt;li&gt;Theses results are bigger than they should be&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dubious step 2: &lt;code class=&quot;highlighter-rouge&quot;&gt;sqrt(1.06^2 + 1.2^2)&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;Pretends that treatment and control groups are independent.&lt;/li&gt;
      &lt;li&gt;sqrt(a^2+b^2) produces a result that is smaller than it should be.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The two errors offset each other. The result is a slight overestimate of SE, close to correct.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-window-to-a-wider-world&quot;&gt;5 Window to a wider world&lt;/h3&gt;

&lt;h4 id=&quot;51-not-everythings-normal-chi-squared-test&quot;&gt;5.1 Not everything’s normal: chi-squared test&lt;/h4&gt;

&lt;p&gt;A categorical data: more than two categories&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Sample of students at a large university:
	- 54 freshmen
	- 40 sophomores
	- 51 juniors
	- 39 seniors
	- 16 graduate
H0: The data are lkie a simple random sample from a large population consisting of 22.5% each of freshmen, sophomores, juniors, and seniors, and 10% graduate students.
H1: The data are not like a simple random sample from the population in the null.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;Compare the observed counts to what the null predicts:&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;F&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;So&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;J&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Se&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;G&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Total&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;observed&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;54&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;40&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;51&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;39&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;16&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;expected, under null&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;o-e&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-6&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;-4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(o-e)^2/e&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1.8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.556&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0.8&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;4.756&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Test statistic = $\displaystyle\sum{\frac{(o - e)^2}{e}}$ over all categories ~ chi-square(X&lt;sup&gt;2&lt;/sup&gt;) distribution, with degrees of freedom = number of categories - 1&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Facts about chi-square distributions
    &lt;ul&gt;
      &lt;li&gt;Values are non-negative&lt;/li&gt;
      &lt;li&gt;expected value = balance point = degrees of freedom&lt;/li&gt;
      &lt;li&gt;SD = sqrt(2 * degrees of freedom)&lt;/li&gt;
      &lt;li&gt;As the degrees of freedom increase, the chi-square curve looks more and more like a normal curve.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;52-how-fisher-used-the-chi-squared-test&quot;&gt;5.2 How Fisher used the chi-squared test&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Test raises questions about the accuracy of Mendel’s data: the deviations from his models were smaller than would be expected by chance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;53-chi-squared-test-for-independence&quot;&gt;5.3 Chi-squared test for independence&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;SRS of students at a large university&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Observed result&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;female&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;male&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;total&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;delared science&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;62&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;21&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;declared other&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;137&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;74&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;211&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;undeclared&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;48&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;58&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;106&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;247&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;153&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;400&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Question: At the university, are gender and major declaration status independent?&lt;/li&gt;
  &lt;li&gt;H0: independent; H1: not independent&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Expected result: $\text{expected count} \approx \frac{\text{row total} \times \text{column total}}{\text{grand total}}$&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;female&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;male&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;total&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;delared science&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;51.25&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;31.75&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;83&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;declared other&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;130.29&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;80.71&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;211&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;undeclared&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;65.45&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;40.55&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;106&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;total&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;247&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;153&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;400&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Add $\frac{(o-e)^{2}}{e}$ over all 3 * 2 cells&lt;/li&gt;
  &lt;li&gt;$\chi^{2} \text{statistic} \approx 19$&lt;/li&gt;
  &lt;li&gt;degrees of freedom = (rows - 1) $\times$ (columns -1) = (3-1)$\times$(2-1) =2&lt;/li&gt;
  &lt;li&gt;p = 7.485183e-05, tiny&lt;/li&gt;
  &lt;li&gt;Conclusion: Not independent&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&quot;appendix-1--the-greek-symbols&quot;&gt;Appendix 1 : The Greek Symbols&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/Greek_Symbol.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D&quot;&gt;https://zh.wikipedia.org/wiki/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;appendix-2--common-distribution&quot;&gt;Appendix 2 : Common Distribution&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/common_distribution_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/common_distribution_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ps: pmf, probability mass function（概率质量函数）; pdf, probability density function（概率密度函数）; mgf, Moment-generating function（动差生成函数）&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&quot;http://www.stat.tamu.edu/~twehrly/611/distab.pdf&quot;&gt;http://www.stat.tamu.edu/~twehrly/611/distab.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;appendix-3-how-to-choose-statistical-test&quot;&gt;Appendix 3: how to choose statistical test&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/how-to-choose-statistic.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;source: &lt;a href=&quot;http://www.graphpad.com/support/faqid/1790/&quot;&gt;http://www.graphpad.com/support/faqid/1790/&lt;/a&gt;ƒ&lt;/p&gt;
</description>
        <pubDate>Tue, 09 May 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/05/09/Stats_MOOC.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/05/09/Stats_MOOC.html</guid>
        
        <category>statistics</category>
        
        <category>mooc</category>
        
        
      </item>
    
      <item>
        <title>PBS</title>
        <description>&lt;h3 id=&quot;what-is-pbs&quot;&gt;What is PBS?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Portable_Batch_System&quot;&gt;Portable Batch System (PBS)&lt;/a&gt; is the name of computer software that performs job scheduling. It has three versions - OpenPBS, TORQUE, PBS Professional.&lt;/p&gt;

&lt;h3 id=&quot;pbs-commands&quot;&gt;PBS Commands&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pbsnodes&lt;/code&gt;: query PBS host or vnode status or mark hosts free or offline&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qstat&lt;/code&gt;: display status of PBS batch jobs, queues, or servers&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qalter&lt;/code&gt;: alter PBS job&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qdel&lt;/code&gt;: deletes PBS jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qrun&lt;/code&gt;: run a PBS batch job now&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qmove&lt;/code&gt;: move PBS batch job&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qhold&lt;/code&gt;: hold PBS batch jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qrls&lt;/code&gt;: release hold on PBS batch jobs&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qsig&lt;/code&gt;: signal PBS batch job&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qsub&lt;/code&gt;: Submit a job&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tracejob&lt;/code&gt;: Report job history&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;common-commands&quot;&gt;Common commands&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;qstat -t&lt;/code&gt;: Displays status information for jobs, job arrays, and subjobs.
&lt;code class=&quot;highlighter-rouge&quot;&gt;qstat -Q&lt;/code&gt;: Display queue status in default format&lt;/p&gt;

&lt;h3 id=&quot;common-pbs-lines&quot;&gt;Common &lt;code class=&quot;highlighter-rouge&quot;&gt;#PBS&lt;/code&gt; lines&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-A&lt;/code&gt;: account string&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-J&lt;/code&gt;: job array&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-N&lt;/code&gt;: job name&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt;: resource list
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;select&lt;/code&gt;: The number of nodes is requested via the select command&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mem&lt;/code&gt;: memory&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ncpus&lt;/code&gt;: cpu, thread&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;walltime&lt;/code&gt;: walltime&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;useful-links&quot;&gt;Useful links&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.pbsworks.com/pdfs/PBSUserGuide14.2.pdf&quot;&gt;PBS Professional User Guide&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Portable_Batch_System&quot;&gt;PBS wiki&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://linuxinfo.physik.hu-berlin.de/pbs.html&quot;&gt;PBS Summary web page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 09 May 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/05/09/PBS.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/05/09/PBS.html</guid>
        
        <category>cs</category>
        
        
      </item>
    
      <item>
        <title>GWAS analysis</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Genome-wide_association_study&quot;&gt;GWAS&lt;/a&gt; is a popular method to detect the genetic variants associated with a trait in different individuals.&lt;/p&gt;

&lt;p&gt;I found a series of four papers written by &lt;a href=&quot;http://www.well.ox.ac.uk/home&quot;&gt;Wellcome Trust Center for Human Genetics&lt;/a&gt; published on &lt;a href=&quot;http://www.nature.com/nprot/index.html&quot;&gt;Nature Protocol&lt;/a&gt;, which is a great resource for beginners (list shown below).&lt;/p&gt;

&lt;p&gt;This blog is the notebook for these four paper.&lt;/p&gt;

&lt;h2 id=&quot;study-design&quot;&gt;Study design&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;phenotype&lt;/li&gt;
  &lt;li&gt;heritability&lt;/li&gt;
  &lt;li&gt;consider the population-based method&lt;/li&gt;
  &lt;li&gt;controls&lt;/li&gt;
  &lt;li&gt;sample size&lt;/li&gt;
  &lt;li&gt;de novo or repliction study&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;data-quality-control&quot;&gt;Data quality control&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Per-individual QC
    &lt;ul&gt;
      &lt;li&gt;identification of individuals with discordant sex information&lt;/li&gt;
      &lt;li&gt;identification of individuals with outlying missing genotype or heterozygosity rates&lt;/li&gt;
      &lt;li&gt;identification of duplicated or related individuals&lt;/li&gt;
      &lt;li&gt;identification of individuals of divergent ancestry&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Per-marker QC
    &lt;ul&gt;
      &lt;li&gt;identification of SNPs with an excessive missing genotype&lt;/li&gt;
      &lt;li&gt;identification of SNPs showing a significant deviation from Hardy-Weinberg equilibrium (HWE)&lt;/li&gt;
      &lt;li&gt;identification of SNPs with significantly different missing genotype rates between cases and controls&lt;/li&gt;
      &lt;li&gt;the removal of all markers with a very low minor allele frequency (MAF)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;paper-list&quot;&gt;Paper list&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Zondervan, K. T., &amp;amp; Cardon, L. R. (2007). &lt;strong&gt;Designing candidate gene and genome-wide case–control association studies.&lt;/strong&gt; Nature Protocols, 2(10), 2492–2501. &lt;a href=&quot;https://doi.org/10.1038/nprot.2007.366&quot;&gt;https://doi.org/10.1038/nprot.2007.366&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Pettersson, F. H., Anderson, C. A., Clarke, G. M., Barrett, J. C., Cardon, L. R., Morris, A. P., &amp;amp; Zondervan, K. T. (2009). &lt;strong&gt;Marker selection for genetic case–control association studies.&lt;/strong&gt; Nature Protocols, 4(5), 743–752. &lt;a href=&quot;https://doi.org/10.1038/nprot.2009.38&quot;&gt;https://doi.org/10.1038/nprot.2009.38&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Anderson, C., Pettersson, F., Clarke, G., Cardon, L., Morris, A., &amp;amp; Zondervan, K. (2010). &lt;strong&gt;Data quality control in genetic case-control association studies.&lt;/strong&gt; Nat Protoc., 5(9), 1564–1573. &lt;a href=&quot;https://doi.org/10.1038/nprot.2010.116&quot;&gt;https://doi.org/10.1038/nprot.2010.116&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Clarke, G. M., Anderson, C. a, Pettersson, F. H., Cardon, L. R., &amp;amp; Andrew, P. (2011). &lt;strong&gt;Basic statistical analysis in genetic case-control studies.&lt;/strong&gt; Nature Protocols, 6(2), 121–133. &lt;a href=&quot;https://doi.org/10.1038/nprot.2010.182.Basic&quot;&gt;https://doi.org/10.1038/nprot.2010.182.Basic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 05 May 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/05/05/GWAS_analysis.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/05/05/GWAS_analysis.html</guid>
        
        <category>GWAS</category>
        
        
      </item>
    
      <item>
        <title>python官方教程目录翻译</title>
        <description>&lt;p&gt;本博客为&lt;a href=&quot;https://docs.python.org/3/tutorial/&quot;&gt;python tutorial目录&lt;/a&gt;的翻译。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Whetting Your Appetite（开胃菜）&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Using the Python Interpreter（使用pyhon解析器）
        &lt;ul&gt;
          &lt;li&gt;2.1. Invoking the Interpreter（触发解析器）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;2.1.1. Argument Passing（传递参数）&lt;/li&gt;
          &lt;li&gt;2.1.2. Interactive Mode（交互模式）
    - 2.2. The Interpreter and Its Environment（解析器及其环境）&lt;/li&gt;
          &lt;li&gt;2.2.1. Source Code Encoding（源码编码）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;An Informal Introduction to Python（非正式python简介）
        &lt;ul&gt;
          &lt;li&gt;3.1. Using Python as a Calculator（把python当做计算器）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;3.1.1. Numbers（数字）&lt;/li&gt;
          &lt;li&gt;3.1.2. Strings（字符）&lt;/li&gt;
          &lt;li&gt;3.1.3. Lists（列表）
    - 3.2. First Steps Towards Programming（编程第一步）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;More Control Flow Tools（更多关于流控制工具）
        &lt;ul&gt;
          &lt;li&gt;4.1. &lt;code class=&quot;highlighter-rouge&quot;&gt;if&lt;/code&gt; Statements（if语句）&lt;/li&gt;
          &lt;li&gt;4.2. &lt;code class=&quot;highlighter-rouge&quot;&gt;for&lt;/code&gt; Statements（for语句）&lt;/li&gt;
          &lt;li&gt;4.3. The &lt;code class=&quot;highlighter-rouge&quot;&gt;range()&lt;/code&gt; Function（range函数）&lt;/li&gt;
          &lt;li&gt;4.4. &lt;code class=&quot;highlighter-rouge&quot;&gt;break&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;continue&lt;/code&gt; Statements, and &lt;code class=&quot;highlighter-rouge&quot;&gt;else&lt;/code&gt; Clauses on Loops（循环中的break、continue语句，else从句）&lt;/li&gt;
          &lt;li&gt;4.5. &lt;code class=&quot;highlighter-rouge&quot;&gt;pass&lt;/code&gt; Statements（pass语句）&lt;/li&gt;
          &lt;li&gt;4.6. Defining Functions（定义函数）&lt;/li&gt;
          &lt;li&gt;4.7. More on Defining Functions（更多关于定义函数）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;4.7.1. Default Argument Values（默认参数值）&lt;/li&gt;
          &lt;li&gt;4.7.2. Keyword Arguments（关键词参数）&lt;/li&gt;
          &lt;li&gt;4.7.3. Arbitrary Argument Lists（任意参数列表）&lt;/li&gt;
          &lt;li&gt;4.7.4. Unpacking Argument Lists（打开参数列表）&lt;/li&gt;
          &lt;li&gt;4.7.5. Lambda Expressions（Lambda表达式）&lt;/li&gt;
          &lt;li&gt;4.7.6. Documentation Strings（文档字符串）&lt;/li&gt;
          &lt;li&gt;4.7.7. Function Annotations（函数注释）
    - 4.8. Intermezzo: Coding Style（间奏曲：编码风格）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Data Structures（数据结构）
        &lt;ul&gt;
          &lt;li&gt;5.1. More on Lists（更多关于列表）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;5.1.1. Using Lists as Stacks（使用列表作为栈）&lt;/li&gt;
          &lt;li&gt;5.1.2. Using Lists as Queues（使用文档作为队列）&lt;/li&gt;
          &lt;li&gt;5.1.3. List Comprehensions（列表推导式）&lt;/li&gt;
          &lt;li&gt;5.1.4. Nested List Comprehensions（嵌套式列表推导式）
    - 5.2. The &lt;code class=&quot;highlighter-rouge&quot;&gt;del&lt;/code&gt; statement（del语句）
    - 5.3. Tuples and Sequences（元组和序列）
    - 5.4. Sets（集合）
    - 5.5. Dictionaries（字典）
    - 5.6. Looping Techniques（循环技术）
    - 5.7. More on Conditions（更多关于条件）
    - 5.8. Comparing Sequences and Other Types（序列和其他类型的比较）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Modules（模块）
        &lt;ul&gt;
          &lt;li&gt;6.1. More on Modules（更多关于模块）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;6.1.1. Executing modules as scripts（像脚本一样执行模块）&lt;/li&gt;
          &lt;li&gt;6.1.2. The Module Search Path（模块搜索路径）&lt;/li&gt;
          &lt;li&gt;6.1.3. “Compiled” Python files（编译后的python文件）
    - 6.2. Standard Modules（标准模块）
    - 6.3. The &lt;code class=&quot;highlighter-rouge&quot;&gt;dir()&lt;/code&gt; Function（dir函数）
    - 6.4. Packages（包）&lt;/li&gt;
          &lt;li&gt;6.4.1. Importing * From a Package（从一个包引用*）&lt;/li&gt;
          &lt;li&gt;6.4.2. Intra-package References（包内引用）&lt;/li&gt;
          &lt;li&gt;6.4.3. Packages in Multiple Directories（多个文件夹中的包）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Input and Output（输入和输出）
        &lt;ul&gt;
          &lt;li&gt;7.1. Fancier Output Formatting（更好的输出格式化）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;7.1.1. Old string formatting（旧的字符串格式化）
    - 7.2. Reading and Writing Files（读和写文件）&lt;/li&gt;
          &lt;li&gt;7.2.1. Methods of File Objects（文件对象的方法）&lt;/li&gt;
          &lt;li&gt;7.2.2. Saving structured data with json（使用json保存结构化数据）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Errors and Exceptions（错误和异常）
        &lt;ul&gt;
          &lt;li&gt;8.1. Syntax Errors（语法错误）&lt;/li&gt;
          &lt;li&gt;8.2. Exceptions（异常）&lt;/li&gt;
          &lt;li&gt;8.3. Handling Exceptions（处理异常）&lt;/li&gt;
          &lt;li&gt;8.4. Raising Exceptions（报异常）&lt;/li&gt;
          &lt;li&gt;8.5. User-defined Exceptions（用户定义的异常）&lt;/li&gt;
          &lt;li&gt;8.6. Defining Clean-up Actions（定义清理操作）&lt;/li&gt;
          &lt;li&gt;8.7. Predefined Clean-up Actions（预定义清理操作）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Classes（类）
        &lt;ul&gt;
          &lt;li&gt;9.1. A Word About Names and Objects（关于命名和对象）&lt;/li&gt;
          &lt;li&gt;9.2. Python Scopes and Namespaces（Python的作用域和命名空间）&lt;/li&gt;
          &lt;li&gt;9.2.1. Scopes and Namespaces Example（作用域和命名空间例子）&lt;/li&gt;
          &lt;li&gt;9.3. A First Look at Classes（初步关于类）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;9.3.1. Class Definition Syntax（类定义的语法）&lt;/li&gt;
          &lt;li&gt;9.3.2. Class Objects（类对象）&lt;/li&gt;
          &lt;li&gt;9.3.3. Instance Objects（实例对象）&lt;/li&gt;
          &lt;li&gt;9.3.4. Method Objects（方法对象）&lt;/li&gt;
          &lt;li&gt;9.3.5. Class and Instance Variables（类和实例变量）
    - 9.4. Random Remarks（自由标记）
    - 9.5. Inheritance（继承）&lt;/li&gt;
          &lt;li&gt;9.5.1. Multiple Inheritance（多继承）
    - 9.6. Private Variables（私有变量）
    - 9.7. Odds and Ends（零杂技巧）
    - 9.8. Iterators（迭代器）
    - 9.9. Generators（生成器）
    - 9.10. Generator Expressions（生成器表达式）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Brief Tour of the Standard Library（标准程序库简要浏览）
        &lt;ul&gt;
          &lt;li&gt;10.1. Operating System Interface（操作系统接口）&lt;/li&gt;
          &lt;li&gt;10.2. File Wildcards（文件通配）&lt;/li&gt;
          &lt;li&gt;10.3. Command Line Arguments（命令行参数）&lt;/li&gt;
          &lt;li&gt;10.4. Error Output Redirection and Program Termination（错误输出重定向和程序结束）&lt;/li&gt;
          &lt;li&gt;10.5. String Pattern Matching（字符串模式比对）&lt;/li&gt;
          &lt;li&gt;10.6. Mathematics（数学）&lt;/li&gt;
          &lt;li&gt;10.7. Internet Access（连接互联网）&lt;/li&gt;
          &lt;li&gt;10.8. Dates and Times（日期和时间）&lt;/li&gt;
          &lt;li&gt;10.9. Data Compression（数据压缩）&lt;/li&gt;
          &lt;li&gt;10.10. Performance Measurement（性能测试）&lt;/li&gt;
          &lt;li&gt;10.11. Quality Control（质控、测试）&lt;/li&gt;
          &lt;li&gt;10.12. Batteries Included（自带电池）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Brief Tour of the Standard Library — Part II（标准程序库简要浏览-II）
        &lt;ul&gt;
          &lt;li&gt;11.1. Output Formatting（输出格式化）&lt;/li&gt;
          &lt;li&gt;11.2. Templating（模板）&lt;/li&gt;
          &lt;li&gt;11.3. Working with Binary Data Record Layouts（二进制数据布局）&lt;/li&gt;
          &lt;li&gt;11.4. Multi-threading（多线程）&lt;/li&gt;
          &lt;li&gt;11.5. Logging（日志）&lt;/li&gt;
          &lt;li&gt;11.6. Weak References（弱引用）&lt;/li&gt;
          &lt;li&gt;11.7. Tools for Working with Lists（列表相关工具）&lt;/li&gt;
          &lt;li&gt;11.8. Decimal Floating Point Arithmetic（十进制浮点运算）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Virtual Environments and Packages（虚拟环境和包）
        &lt;ul&gt;
          &lt;li&gt;12.1. Introduction（简介）&lt;/li&gt;
          &lt;li&gt;12.2. Creating Virtual Environments（创建一个虚拟环境）&lt;/li&gt;
          &lt;li&gt;12.3. Managing Packages with &lt;code class=&quot;highlighter-rouge&quot;&gt;pip&lt;/code&gt;（使用pip管理包）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;What Now?(下一步)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Interactive Input Editing and History Substitution（交互性输入编辑和历史替换）
        &lt;ul&gt;
          &lt;li&gt;14.1. Tab Completion and History Editing（Tab补全和历史修改）&lt;/li&gt;
          &lt;li&gt;14.2. Alternatives to the Interactive Interpreter（其他交互式解析器）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Floating Point Arithmetic: Issues and Limitations（浮点数运算：问题和局限）
        &lt;ul&gt;
          &lt;li&gt;15.1. Representation Error（表现形式错误）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;Appendix（附录）
        &lt;ul&gt;
          &lt;li&gt;16.1. Interactive Mode（交互模式）&lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
          &lt;li&gt;16.1.1. Error Handling（错误处理）&lt;/li&gt;
          &lt;li&gt;16.1.2. Executable Python Scripts（可执行的python脚本）&lt;/li&gt;
          &lt;li&gt;16.1.3. The Interactive Startup File（交互设置文件）&lt;/li&gt;
          &lt;li&gt;16.1.4. The Customization Modules（自定义的模块）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 23 Mar 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/03/23/Python_tutorial.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/23/Python_tutorial.html</guid>
        
        <category>cs</category>
        
        <category>python</category>
        
        
      </item>
    
      <item>
        <title>Edx-python学习笔记(6.002)</title>
        <description>&lt;p&gt;List of Lecture Topics&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lecture 1- Optimization and Knapsack Problem
    &lt;ul&gt;
      &lt;li&gt;Computational models&lt;/li&gt;
      &lt;li&gt;Intro to optimization&lt;/li&gt;
      &lt;li&gt;0/1 Knapsack Problem&lt;/li&gt;
      &lt;li&gt;Greedy solutions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 2 - Decision Trees and Dynamic Programming
    &lt;ul&gt;
      &lt;li&gt;Decision tree solution to knapsack&lt;/li&gt;
      &lt;li&gt;Dynamic programming and knapsack&lt;/li&gt;
      &lt;li&gt;Divide and conquer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 3 - Graphs
    &lt;ul&gt;
      &lt;li&gt;Graph problems&lt;/li&gt;
      &lt;li&gt;Shortest path&lt;/li&gt;
      &lt;li&gt;Depth first search&lt;/li&gt;
      &lt;li&gt;Breadth first search&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 4 - Plotting
    &lt;ul&gt;
      &lt;li&gt;Visualizing Results&lt;/li&gt;
      &lt;li&gt;Overlapping Displays&lt;/li&gt;
      &lt;li&gt;Adding More Documentation&lt;/li&gt;
      &lt;li&gt;Changing Data Display&lt;/li&gt;
      &lt;li&gt;An Example&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 5 - Stochastic Thinking
    &lt;ul&gt;
      &lt;li&gt;Rolling a Die&lt;/li&gt;
      &lt;li&gt;Random walks&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 6 - Random Walks
    &lt;ul&gt;
      &lt;li&gt;Drunk walk&lt;/li&gt;
      &lt;li&gt;Biased random walks&lt;/li&gt;
      &lt;li&gt;Treacherous fields&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 7 - Inferential Statistics
    &lt;ul&gt;
      &lt;li&gt;Probabilities&lt;/li&gt;
      &lt;li&gt;Confidence intervals&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 8 - Monte Carlo Simulation&lt;/li&gt;
  &lt;li&gt;Lecture 9 - Monte Carlo Simulations
    &lt;ul&gt;
      &lt;li&gt;Sampling&lt;/li&gt;
      &lt;li&gt;Standard error&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 10 - Experimental Data
    &lt;ul&gt;
      &lt;li&gt;Errors in Experimental Observations&lt;/li&gt;
      &lt;li&gt;Curve Fitting&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 11 - Experimental Data
    &lt;ul&gt;
      &lt;li&gt;Goodness of Fit&lt;/li&gt;
      &lt;li&gt;Using a Model for Predictions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 12 - Machine Learning
    &lt;ul&gt;
      &lt;li&gt;Feature Vectors&lt;/li&gt;
      &lt;li&gt;Distance Metrics&lt;/li&gt;
      &lt;li&gt;Clustering&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lecture 13 - Statistical Fallacies
    &lt;ul&gt;
      &lt;li&gt;Misusing Statistics&lt;/li&gt;
      &lt;li&gt;Garbage In Garbage Out&lt;/li&gt;
      &lt;li&gt;Data Enhancement&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 09 Mar 2017 00:00:00 +1000</pubDate>
        <link>http://localhost:4000/2017/03/09/MITx_Python2.html</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/09/MITx_Python2.html</guid>
        
        <category>cs</category>
        
        <category>mooc笔记</category>
        
        <category>python</category>
        
        
      </item>
    
  </channel>
</rss>
